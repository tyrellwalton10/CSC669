{
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        },
        "accelerator": "TPU",
        "colab": {
            "authorship_tag": "ABX9TyPO8AE78EDcqk/Xeqsq5ATg",
            "machine_shape": "hm",
            "provenance": []
        },
        "gpuClass": "standard",
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "1ae5a6cb2ac44a9ca3d543301fcd075e": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_module_version": "1.5.0",
                    "model_name": "DescriptionStyleModel",
                    "state": {
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "DescriptionStyleModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "StyleView",
                        "description_width": ""
                    }
                },
                "35abb842c5504d3f9203c588cce3ce91": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_module_version": "1.5.0",
                    "model_name": "FloatProgressModel",
                    "state": {
                        "_dom_classes": [],
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "FloatProgressModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/controls",
                        "_view_module_version": "1.5.0",
                        "_view_name": "ProgressView",
                        "bar_style": "success",
                        "description": "",
                        "description_tooltip": null,
                        "layout": "IPY_MODEL_8271ffadbbdc42d99558b0f882c617b8",
                        "max": 1,
                        "min": 0,
                        "orientation": "horizontal",
                        "style": "IPY_MODEL_c4e40b89a98a457ebf01fb2ed32d3b6b",
                        "value": 1
                    }
                },
                "37ba4d713a014f37a33ce41ee6efb019": {
                    "model_module": "@jupyter-widgets/base",
                    "model_module_version": "1.2.0",
                    "model_name": "LayoutModel",
                    "state": {
                        "_model_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.2.0",
                        "_model_name": "LayoutModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "LayoutView",
                        "align_content": null,
                        "align_items": null,
                        "align_self": null,
                        "border": null,
                        "bottom": null,
                        "display": null,
                        "flex": null,
                        "flex_flow": null,
                        "grid_area": null,
                        "grid_auto_columns": null,
                        "grid_auto_flow": null,
                        "grid_auto_rows": null,
                        "grid_column": null,
                        "grid_gap": null,
                        "grid_row": null,
                        "grid_template_areas": null,
                        "grid_template_columns": null,
                        "grid_template_rows": null,
                        "height": null,
                        "justify_content": null,
                        "justify_items": null,
                        "left": null,
                        "margin": null,
                        "max_height": null,
                        "max_width": null,
                        "min_height": null,
                        "min_width": null,
                        "object_fit": null,
                        "object_position": null,
                        "order": null,
                        "overflow": null,
                        "overflow_x": null,
                        "overflow_y": null,
                        "padding": null,
                        "right": null,
                        "top": null,
                        "visibility": null,
                        "width": null
                    }
                },
                "4bdc2ccfca5c4caa8deaf9d7c0a66354": {
                    "model_module": "@jupyter-widgets/base",
                    "model_module_version": "1.2.0",
                    "model_name": "LayoutModel",
                    "state": {
                        "_model_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.2.0",
                        "_model_name": "LayoutModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "LayoutView",
                        "align_content": null,
                        "align_items": null,
                        "align_self": null,
                        "border": null,
                        "bottom": null,
                        "display": null,
                        "flex": null,
                        "flex_flow": null,
                        "grid_area": null,
                        "grid_auto_columns": null,
                        "grid_auto_flow": null,
                        "grid_auto_rows": null,
                        "grid_column": null,
                        "grid_gap": null,
                        "grid_row": null,
                        "grid_template_areas": null,
                        "grid_template_columns": null,
                        "grid_template_rows": null,
                        "height": null,
                        "justify_content": null,
                        "justify_items": null,
                        "left": null,
                        "margin": null,
                        "max_height": null,
                        "max_width": null,
                        "min_height": null,
                        "min_width": null,
                        "object_fit": null,
                        "object_position": null,
                        "order": null,
                        "overflow": null,
                        "overflow_x": null,
                        "overflow_y": null,
                        "padding": null,
                        "right": null,
                        "top": null,
                        "visibility": null,
                        "width": null
                    }
                },
                "760b9765b6ed4bcda85622c3dce4ff2d": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_module_version": "1.5.0",
                    "model_name": "HTMLModel",
                    "state": {
                        "_dom_classes": [],
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "HTMLModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/controls",
                        "_view_module_version": "1.5.0",
                        "_view_name": "HTMLView",
                        "description": "",
                        "description_tooltip": null,
                        "layout": "IPY_MODEL_37ba4d713a014f37a33ce41ee6efb019",
                        "placeholder": "​",
                        "style": "IPY_MODEL_1ae5a6cb2ac44a9ca3d543301fcd075e",
                        "value": " 10222/? [31:39&lt;00:00,  5.68it/s]"
                    }
                },
                "8271ffadbbdc42d99558b0f882c617b8": {
                    "model_module": "@jupyter-widgets/base",
                    "model_module_version": "1.2.0",
                    "model_name": "LayoutModel",
                    "state": {
                        "_model_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.2.0",
                        "_model_name": "LayoutModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "LayoutView",
                        "align_content": null,
                        "align_items": null,
                        "align_self": null,
                        "border": null,
                        "bottom": null,
                        "display": null,
                        "flex": null,
                        "flex_flow": null,
                        "grid_area": null,
                        "grid_auto_columns": null,
                        "grid_auto_flow": null,
                        "grid_auto_rows": null,
                        "grid_column": null,
                        "grid_gap": null,
                        "grid_row": null,
                        "grid_template_areas": null,
                        "grid_template_columns": null,
                        "grid_template_rows": null,
                        "height": null,
                        "justify_content": null,
                        "justify_items": null,
                        "left": null,
                        "margin": null,
                        "max_height": null,
                        "max_width": null,
                        "min_height": null,
                        "min_width": null,
                        "object_fit": null,
                        "object_position": null,
                        "order": null,
                        "overflow": null,
                        "overflow_x": null,
                        "overflow_y": null,
                        "padding": null,
                        "right": null,
                        "top": null,
                        "visibility": null,
                        "width": "20px"
                    }
                },
                "8d7da8de71384cb49fe5891cd757dce9": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_module_version": "1.5.0",
                    "model_name": "HTMLModel",
                    "state": {
                        "_dom_classes": [],
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "HTMLModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/controls",
                        "_view_module_version": "1.5.0",
                        "_view_name": "HTMLView",
                        "description": "",
                        "description_tooltip": null,
                        "layout": "IPY_MODEL_4bdc2ccfca5c4caa8deaf9d7c0a66354",
                        "placeholder": "​",
                        "style": "IPY_MODEL_a971398fb5484627b8c1f958e5a96bda",
                        "value": ""
                    }
                },
                "a971398fb5484627b8c1f958e5a96bda": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_module_version": "1.5.0",
                    "model_name": "DescriptionStyleModel",
                    "state": {
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "DescriptionStyleModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "StyleView",
                        "description_width": ""
                    }
                },
                "c4e40b89a98a457ebf01fb2ed32d3b6b": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_module_version": "1.5.0",
                    "model_name": "ProgressStyleModel",
                    "state": {
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "ProgressStyleModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "StyleView",
                        "bar_color": null,
                        "description_width": ""
                    }
                },
                "fa7911d9ddf649b998b49d6baa9e53ad": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_module_version": "1.5.0",
                    "model_name": "HBoxModel",
                    "state": {
                        "_dom_classes": [],
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "HBoxModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/controls",
                        "_view_module_version": "1.5.0",
                        "_view_name": "HBoxView",
                        "box_style": "",
                        "children": [
                            "IPY_MODEL_8d7da8de71384cb49fe5891cd757dce9",
                            "IPY_MODEL_35abb842c5504d3f9203c588cce3ce91",
                            "IPY_MODEL_760b9765b6ed4bcda85622c3dce4ff2d"
                        ],
                        "layout": "IPY_MODEL_fd1301ff7b6e455eabc0e0a7267b52b6"
                    }
                },
                "fd1301ff7b6e455eabc0e0a7267b52b6": {
                    "model_module": "@jupyter-widgets/base",
                    "model_module_version": "1.2.0",
                    "model_name": "LayoutModel",
                    "state": {
                        "_model_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.2.0",
                        "_model_name": "LayoutModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "LayoutView",
                        "align_content": null,
                        "align_items": null,
                        "align_self": null,
                        "border": null,
                        "bottom": null,
                        "display": null,
                        "flex": null,
                        "flex_flow": null,
                        "grid_area": null,
                        "grid_auto_columns": null,
                        "grid_auto_flow": null,
                        "grid_auto_rows": null,
                        "grid_column": null,
                        "grid_gap": null,
                        "grid_row": null,
                        "grid_template_areas": null,
                        "grid_template_columns": null,
                        "grid_template_rows": null,
                        "height": null,
                        "justify_content": null,
                        "justify_items": null,
                        "left": null,
                        "margin": null,
                        "max_height": null,
                        "max_width": null,
                        "min_height": null,
                        "min_width": null,
                        "object_fit": null,
                        "object_position": null,
                        "order": null,
                        "overflow": null,
                        "overflow_x": null,
                        "overflow_y": null,
                        "padding": null,
                        "right": null,
                        "top": null,
                        "visibility": null,
                        "width": null
                    }
                }
            }
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "Change Jupyter them"
            ],
            "metadata": {
                "azdata_cell_guid": "78bb1b0c-845e-413a-8180-8cb957dad38c"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "!jt -t chesterish"
            ],
            "metadata": {
                "azdata_cell_guid": "5ba51342-5ce3-4768-b76f-ab0b7a70f43e",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": [
                "Intall tensorflow"
            ],
            "metadata": {
                "azdata_cell_guid": "7546ec32-0c5d-4694-9db4-b4578ed92517"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "!pip install tensorflow"
            ],
            "metadata": {
                "azdata_cell_guid": "20749347-6d39-46c0-bd63-37d9dd488e9d",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Requirement already satisfied: tensorflow in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (2.12.0)\nRequirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\nRequirement already satisfied: six>=1.12.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\nRequirement already satisfied: setuptools in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.6.3)\nRequirement already satisfied: h5py>=2.9.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\nRequirement already satisfied: jax>=0.3.15 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\nRequirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\nRequirement already satisfied: astunparse>=1.6.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.3)\nRequirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\nRequirement already satisfied: absl-py>=1.0.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\nRequirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\nRequirement already satisfied: packaging in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (22.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\nRequirement already satisfied: libclang>=13.0.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\nRequirement already satisfied: termcolor>=1.1.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.4.0)\nRequirement already satisfied: flatbuffers>=2.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\nRequirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\nRequirement already satisfied: scipy>=1.7 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\nRequirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\nRequirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\nRequirement already satisfied: markdown>=2.6.8 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rthibodeaux\\appdata\\local\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "Imported modules for data exploration, manipulation, and model building."
            ],
            "metadata": {
                "id": "xTbzZ9Isc0LQ",
                "azdata_cell_guid": "33ee0727-d754-4806-a20c-78e93b414607"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import os\n",
                "from tqdm.notebook import tqdm_notebook as tqdm\n",
                "from sklearn.model_selection import train_test_split\n",
                "import tensorflow as tf\n",
                "from keras.models import Sequential, Model\n",
                "from keras.utils import to_categorical\n",
                "from keras.layers import RepeatVector, Input, Dense, Flatten, AveragePooling2D, Dropout\n",
                "from keras.applications.vgg16 import VGG16, decode_predictions, preprocess_input\n",
                "from keras.applications.mobilenet import MobileNet, decode_predictions, preprocess_input\n",
                "from keras.applications.densenet import DenseNet121, decode_predictions, preprocess_input\n",
                "from keras.applications.efficientnet import EfficientNetB0, decode_predictions, preprocess_input"
            ],
            "metadata": {
                "executionInfo": {
                    "elapsed": 105,
                    "status": "ok",
                    "timestamp": 1680070857550,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "s8Opau0c5s7i",
                "azdata_cell_guid": "ae87fdc0-fcb7-43c9-a7c1-9adfe32df47a",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "markdown",
            "source": [
                "Mounted my google drive for ease of access to dog images (If not on jupyter notebook)."
            ],
            "metadata": {
                "id": "xZko8bFidDJZ",
                "azdata_cell_guid": "9e5712ff-4fe8-4bb5-858d-d19f8fdcbea5"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "#drive.mount('/content/gdrive')"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 15909,
                    "status": "ok",
                    "timestamp": 1680070873740,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "QkYXnJpLg28d",
                "outputId": "68b1d6af-f15a-4a21-8f75-c913ebe7f123",
                "azdata_cell_guid": "e3778d6b-ff21-4b90-8962-e0b32dfa9414",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "Created variables for training training data, testing data, and labels."
            ],
            "metadata": {
                "id": "arzg3W1ldMfs",
                "azdata_cell_guid": "9abed371-afd0-4750-b15b-c0d6f79c4033"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "data = 'train'\n",
                "test = 'test'\n",
                "labels = 'labels.csv'"
            ],
            "metadata": {
                "executionInfo": {
                    "elapsed": 4,
                    "status": "ok",
                    "timestamp": 1680070873740,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "N9Ipr_6q78dP",
                "azdata_cell_guid": "c141942f-acc3-4c39-acd6-8c878786d625",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": [
                "Reading the labels in the labels.csv file and adding a column for the path of each image in the training dataset."
            ],
            "metadata": {
                "id": "961Zv6ROdjT2",
                "azdata_cell_guid": "758a38fd-ad5a-42fa-b911-29f7f61a2c5f"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "labels_csv = pd.read_csv('labels.csv')\n",
                "labels_csv[\"path\"] = 'train/'+ labels_csv[\"id\"]+\".jpg\"\n",
                "labels_csv.head(30)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 363
                },
                "executionInfo": {
                    "elapsed": 213,
                    "status": "ok",
                    "timestamp": 1680070873950,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "TI_7phn78U-6",
                "outputId": "657f0ea8-fa1e-4537-9d90-4e77bca05813",
                "tags": [],
                "azdata_cell_guid": "2d435871-c297-4aa3-9ef5-d5af67675a9f",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 7,
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>breed</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n      <td>boston_bull</td>\n      <td>train/000bec180eb18c7604dcecc8fe0dba07.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n      <td>dingo</td>\n      <td>train/001513dfcb2ffafc82cccf4d8bbaba97.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001cdf01b096e06d78e9e5112d419397</td>\n      <td>pekinese</td>\n      <td>train/001cdf01b096e06d78e9e5112d419397.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n      <td>bluetick</td>\n      <td>train/00214f311d5d2247d5dfe4fe24b2303d.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n      <td>golden_retriever</td>\n      <td>train/0021f9ceb3235effd7fcde7f7538ed62.jpg</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>002211c81b498ef88e1b40b9abf84e1d</td>\n      <td>bedlington_terrier</td>\n      <td>train/002211c81b498ef88e1b40b9abf84e1d.jpg</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>00290d3e1fdd27226ba27a8ce248ce85</td>\n      <td>bedlington_terrier</td>\n      <td>train/00290d3e1fdd27226ba27a8ce248ce85.jpg</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>002a283a315af96eaea0e28e7163b21b</td>\n      <td>borzoi</td>\n      <td>train/002a283a315af96eaea0e28e7163b21b.jpg</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>003df8b8a8b05244b1d920bb6cf451f9</td>\n      <td>basenji</td>\n      <td>train/003df8b8a8b05244b1d920bb6cf451f9.jpg</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n      <td>scottish_deerhound</td>\n      <td>train/0042188c895a2f14ef64a918ed9c7b64.jpg</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>004396df1acd0f1247b740ca2b14616e</td>\n      <td>shetland_sheepdog</td>\n      <td>train/004396df1acd0f1247b740ca2b14616e.jpg</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0067dc3eab0b3c3ef0439477624d85d6</td>\n      <td>walker_hound</td>\n      <td>train/0067dc3eab0b3c3ef0439477624d85d6.jpg</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>00693b8bc2470375cc744a6391d397ec</td>\n      <td>maltese_dog</td>\n      <td>train/00693b8bc2470375cc744a6391d397ec.jpg</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>006cc3ddb9dc1bd827479569fcdc52dc</td>\n      <td>bluetick</td>\n      <td>train/006cc3ddb9dc1bd827479569fcdc52dc.jpg</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0075dc49dab4024d12fafe67074d8a81</td>\n      <td>norfolk_terrier</td>\n      <td>train/0075dc49dab4024d12fafe67074d8a81.jpg</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>00792e341f3c6eb33663e415d0715370</td>\n      <td>african_hunting_dog</td>\n      <td>train/00792e341f3c6eb33663e415d0715370.jpg</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>007b5a16db9d9ff9d7ad39982703e429</td>\n      <td>wire-haired_fox_terrier</td>\n      <td>train/007b5a16db9d9ff9d7ad39982703e429.jpg</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>007b8a07882822475a4ce6581e70b1f8</td>\n      <td>redbone</td>\n      <td>train/007b8a07882822475a4ce6581e70b1f8.jpg</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>007ff9a78eba2aebb558afea3a51c469</td>\n      <td>lakeland_terrier</td>\n      <td>train/007ff9a78eba2aebb558afea3a51c469.jpg</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>008887054b18ba3c7601792b6a453cc3</td>\n      <td>boxer</td>\n      <td>train/008887054b18ba3c7601792b6a453cc3.jpg</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>008b1271ed1addaccf93783b39deab45</td>\n      <td>doberman</td>\n      <td>train/008b1271ed1addaccf93783b39deab45.jpg</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>008ba178d6dfc1a583617470d19c1673</td>\n      <td>otterhound</td>\n      <td>train/008ba178d6dfc1a583617470d19c1673.jpg</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>009509be3ca7cce0ff9e37c8b09b1125</td>\n      <td>otterhound</td>\n      <td>train/009509be3ca7cce0ff9e37c8b09b1125.jpg</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0097c6242c6f3071762d9f85c3ef1b2f</td>\n      <td>bedlington_terrier</td>\n      <td>train/0097c6242c6f3071762d9f85c3ef1b2f.jpg</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>00a338a92e4e7bf543340dc849230e75</td>\n      <td>dingo</td>\n      <td>train/00a338a92e4e7bf543340dc849230e75.jpg</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>00a366d4b4a9bbb6c8a63126697b7656</td>\n      <td>golden_retriever</td>\n      <td>train/00a366d4b4a9bbb6c8a63126697b7656.jpg</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>00a862390341c5be090dd72bd2bc19ef</td>\n      <td>standard_schnauzer</td>\n      <td>train/00a862390341c5be090dd72bd2bc19ef.jpg</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>00b7d114bc5166a629a3cc03d9329120</td>\n      <td>irish_water_spaniel</td>\n      <td>train/00b7d114bc5166a629a3cc03d9329120.jpg</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>00ba244566e36e0af3d979320fd3017f</td>\n      <td>black-and-tan_coonhound</td>\n      <td>train/00ba244566e36e0af3d979320fd3017f.jpg</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>00bee065dcec471f26394855c5c2f3de</td>\n      <td>cairn</td>\n      <td>train/00bee065dcec471f26394855c5c2f3de.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                                  id                    breed  \\\n0   000bec180eb18c7604dcecc8fe0dba07              boston_bull   \n1   001513dfcb2ffafc82cccf4d8bbaba97                    dingo   \n2   001cdf01b096e06d78e9e5112d419397                 pekinese   \n3   00214f311d5d2247d5dfe4fe24b2303d                 bluetick   \n4   0021f9ceb3235effd7fcde7f7538ed62         golden_retriever   \n5   002211c81b498ef88e1b40b9abf84e1d       bedlington_terrier   \n6   00290d3e1fdd27226ba27a8ce248ce85       bedlington_terrier   \n7   002a283a315af96eaea0e28e7163b21b                   borzoi   \n8   003df8b8a8b05244b1d920bb6cf451f9                  basenji   \n9   0042188c895a2f14ef64a918ed9c7b64       scottish_deerhound   \n10  004396df1acd0f1247b740ca2b14616e        shetland_sheepdog   \n11  0067dc3eab0b3c3ef0439477624d85d6             walker_hound   \n12  00693b8bc2470375cc744a6391d397ec              maltese_dog   \n13  006cc3ddb9dc1bd827479569fcdc52dc                 bluetick   \n14  0075dc49dab4024d12fafe67074d8a81          norfolk_terrier   \n15  00792e341f3c6eb33663e415d0715370      african_hunting_dog   \n16  007b5a16db9d9ff9d7ad39982703e429  wire-haired_fox_terrier   \n17  007b8a07882822475a4ce6581e70b1f8                  redbone   \n18  007ff9a78eba2aebb558afea3a51c469         lakeland_terrier   \n19  008887054b18ba3c7601792b6a453cc3                    boxer   \n20  008b1271ed1addaccf93783b39deab45                 doberman   \n21  008ba178d6dfc1a583617470d19c1673               otterhound   \n22  009509be3ca7cce0ff9e37c8b09b1125               otterhound   \n23  0097c6242c6f3071762d9f85c3ef1b2f       bedlington_terrier   \n24  00a338a92e4e7bf543340dc849230e75                    dingo   \n25  00a366d4b4a9bbb6c8a63126697b7656         golden_retriever   \n26  00a862390341c5be090dd72bd2bc19ef       standard_schnauzer   \n27  00b7d114bc5166a629a3cc03d9329120      irish_water_spaniel   \n28  00ba244566e36e0af3d979320fd3017f  black-and-tan_coonhound   \n29  00bee065dcec471f26394855c5c2f3de                    cairn   \n\n                                          path  \n0   train/000bec180eb18c7604dcecc8fe0dba07.jpg  \n1   train/001513dfcb2ffafc82cccf4d8bbaba97.jpg  \n2   train/001cdf01b096e06d78e9e5112d419397.jpg  \n3   train/00214f311d5d2247d5dfe4fe24b2303d.jpg  \n4   train/0021f9ceb3235effd7fcde7f7538ed62.jpg  \n5   train/002211c81b498ef88e1b40b9abf84e1d.jpg  \n6   train/00290d3e1fdd27226ba27a8ce248ce85.jpg  \n7   train/002a283a315af96eaea0e28e7163b21b.jpg  \n8   train/003df8b8a8b05244b1d920bb6cf451f9.jpg  \n9   train/0042188c895a2f14ef64a918ed9c7b64.jpg  \n10  train/004396df1acd0f1247b740ca2b14616e.jpg  \n11  train/0067dc3eab0b3c3ef0439477624d85d6.jpg  \n12  train/00693b8bc2470375cc744a6391d397ec.jpg  \n13  train/006cc3ddb9dc1bd827479569fcdc52dc.jpg  \n14  train/0075dc49dab4024d12fafe67074d8a81.jpg  \n15  train/00792e341f3c6eb33663e415d0715370.jpg  \n16  train/007b5a16db9d9ff9d7ad39982703e429.jpg  \n17  train/007b8a07882822475a4ce6581e70b1f8.jpg  \n18  train/007ff9a78eba2aebb558afea3a51c469.jpg  \n19  train/008887054b18ba3c7601792b6a453cc3.jpg  \n20  train/008b1271ed1addaccf93783b39deab45.jpg  \n21  train/008ba178d6dfc1a583617470d19c1673.jpg  \n22  train/009509be3ca7cce0ff9e37c8b09b1125.jpg  \n23  train/0097c6242c6f3071762d9f85c3ef1b2f.jpg  \n24  train/00a338a92e4e7bf543340dc849230e75.jpg  \n25  train/00a366d4b4a9bbb6c8a63126697b7656.jpg  \n26  train/00a862390341c5be090dd72bd2bc19ef.jpg  \n27  train/00b7d114bc5166a629a3cc03d9329120.jpg  \n28  train/00ba244566e36e0af3d979320fd3017f.jpg  \n29  train/00bee065dcec471f26394855c5c2f3de.jpg  "
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": [
                "Explored the number of unique breeds in the dataset."
            ],
            "metadata": {
                "id": "NJaoRy_0dv2i",
                "azdata_cell_guid": "9fa2725f-6750-4532-8ca0-5627666245f3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print(len(labels_csv['breed'].unique()))"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 344,
                    "status": "ok",
                    "timestamp": 1680070874292,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "ethnOGejXo5j",
                "outputId": "61925c12-7ae2-433e-828d-3cda2e289343",
                "azdata_cell_guid": "827fbbca-6fe4-4124-8be8-f69eace48446",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "120\n"
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": [
                "1. Create an empty array that matches the shape of the data.\n",
                "2. Iterate through each index/image in the labels.csv file.\n",
                "3. Each iteration follows this process.\n",
                "*   Load image.\n",
                "*   Convert the image to an array.\n",
                "*   Normalize and scale the pixels in the pre-processing process.\n",
                "*   Convert the image array to a batch of arrays to be easily processed by the network - each model has a pre-processing method.\n",
                "*   Store the array in the empty array created earlier."
            ],
            "metadata": {
                "id": "D-vtHfCSd3DV",
                "tags": [],
                "azdata_cell_guid": "c7b080f5-f42f-46f0-8b90-f2d3c21e8830"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x_labels_vgg = np.zeros((labels_csv.shape[0], 128, 128, 3), dtype=np.float32)\n",
                "x_labels_mobile = np.zeros((labels_csv.shape[0], 128, 128, 3), dtype=np.float32)\n",
                "x_labels_dense = np.zeros((labels_csv.shape[0], 128, 128, 3), dtype=np.float32)\n",
                "x_labels_eff = np.zeros((labels_csv.shape[0], 128, 128, 3), dtype=np.float32)\n",
                "\n",
                "for i, index in tqdm(enumerate(labels_csv['path'])):\n",
                "    image = tf.keras.preprocessing.image.load_img(index, target_size=(128,128))\n",
                "\n",
                "    img_array = tf.keras.preprocessing.image.img_to_array(image)\n",
                "\n",
                "    img_array_vgg = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
                "    img_array_vgg = np.expand_dims(img_array_vgg, axis=0)\n",
                "    x_labels_vgg[i] = img_array_vgg\n",
                "\n",
                "    img_array_mobile = tf.keras.applications.mobilenet.preprocess_input(img_array)\n",
                "    img_array_mobile = np.expand_dims(img_array_mobile, axis=0)\n",
                "    x_labels_mobile[i] = img_array_mobile\n",
                "\n",
                "    img_array_dense = tf.keras.applications.densenet.preprocess_input(img_array)\n",
                "    img_array_dense = np.expand_dims(img_array_dense, axis=0)\n",
                "    x_labels_dense[i] = img_array_dense\n",
                "    \n",
                "    img_array_eff = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
                "    img_array_eff = np.expand_dims(img_array_eff, axis=0)\n",
                "    x_labels_eff[i] = img_array_eff"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 49,
                    "referenced_widgets": [
                        "fa7911d9ddf649b998b49d6baa9e53ad",
                        "8d7da8de71384cb49fe5891cd757dce9",
                        "35abb842c5504d3f9203c588cce3ce91",
                        "760b9765b6ed4bcda85622c3dce4ff2d",
                        "fd1301ff7b6e455eabc0e0a7267b52b6",
                        "4bdc2ccfca5c4caa8deaf9d7c0a66354",
                        "a971398fb5484627b8c1f958e5a96bda",
                        "8271ffadbbdc42d99558b0f882c617b8",
                        "c4e40b89a98a457ebf01fb2ed32d3b6b",
                        "37ba4d713a014f37a33ce41ee6efb019",
                        "1ae5a6cb2ac44a9ca3d543301fcd075e"
                    ]
                },
                "executionInfo": {
                    "elapsed": 1899547,
                    "status": "ok",
                    "timestamp": 1680072938023,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "bknGY6IbY1Yi",
                "outputId": "554d54f2-dd95-46ac-c759-ce88f7fb2aa0",
                "azdata_cell_guid": "80189426-aa3f-4a60-a28b-72e07afc0cf3",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "70380a2e68124cb99faa535cd3668270",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": "0it [00:00, ?it/s]"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "One-hot encode the classes, in this case the dog breeds."
            ],
            "metadata": {
                "id": "LkXIy0-ViJ08",
                "azdata_cell_guid": "b5bcd069-93c0-4231-bba1-d87dad676740"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "labels_csv.breed = pd.Categorical(pd.factorize(labels_csv.breed)[0])\n",
                "y_labels = to_categorical(labels_csv[\"breed\"],num_classes=120)\n",
                "print(y_labels)"
            ],
            "metadata": {
                "azdata_cell_guid": "259c3840-3c19-463c-86de-4c56b41ee309",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "[[1. 0. 0. ... 0. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]\n [0. 0. 1. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n"
                }
            ],
            "execution_count": 10
        },
        {
            "cell_type": "markdown",
            "source": [
                "View the shape of x and y labels"
            ],
            "metadata": {
                "azdata_cell_guid": "9a24f263-169e-440e-a8dd-10eed3fe8132"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print(x_labels_vgg.shape)\n",
                "print(y_labels.shape)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 131,
                    "status": "ok",
                    "timestamp": 1680072953188,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "RlFsqbCyl1Ij",
                "outputId": "959fae16-30a0-4921-b21b-f65cacf1d07d",
                "azdata_cell_guid": "2a5136ae-00ec-4bcd-8760-2ee7de9fa931",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "(10222, 128, 128, 3)\n(10222, 120)\n"
                }
            ],
            "execution_count": 11
        },
        {
            "cell_type": "markdown",
            "source": [
                "View encoding."
            ],
            "metadata": {
                "id": "ju0dlBYfib6D",
                "azdata_cell_guid": "57042fb6-71eb-44e2-9fcb-22821acff0d4"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print(x_labels_vgg)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 246,
                    "status": "ok",
                    "timestamp": 1680072955551,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "dJPWdXYkT90n",
                "jupyter": {
                    "outputs_hidden": true
                },
                "outputId": "0ae6c3d6-d802-4e3a-a8ef-b2cd41cf32af",
                "tags": [],
                "azdata_cell_guid": "aaa4434b-c6f9-4542-9253-9b010d2cbc6a",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "[[[[-2.8939003e+01  4.2210007e+00  5.5320000e+01]\n   [-8.0939003e+01 -4.1778999e+01 -2.6800003e+00]\n   [ 1.5060997e+01  6.5221001e+01  9.6320000e+01]\n   ...\n   [ 3.0060997e+01  8.6221001e+01  1.1232000e+02]\n   [-2.6939003e+01  7.8221001e+01  9.6320000e+01]\n   [-4.1939003e+01  2.2221001e+01  4.7320000e+01]]\n\n  [[-6.5939003e+01 -4.6778999e+01 -1.2680000e+01]\n   [ 1.9060997e+01  4.3221001e+01  7.0320000e+01]\n   [ 2.8060997e+01  5.6221001e+01  8.2320000e+01]\n   ...\n   [-3.3939003e+01  1.8221001e+01  5.5320000e+01]\n   [ 6.0609970e+00  7.7221001e+01  1.0532000e+02]\n   [-3.0939003e+01  6.0221001e+01  8.8320000e+01]]\n\n  [[-5.1939003e+01 -2.1778999e+01  1.4320000e+01]\n   [-3.1939003e+01  2.2100067e-01  3.7320000e+01]\n   [-4.1939003e+01 -1.2778999e+01  2.7320000e+01]\n   ...\n   [-7.1939003e+01 -7.7899933e-01  4.4320000e+01]\n   [-2.7939003e+01  3.0221001e+01  6.1320000e+01]\n   [-3.3939003e+01  5.8221001e+01  9.2320000e+01]]\n\n  ...\n\n  [[-1.7939003e+01  2.2210007e+00  6.8320000e+01]\n   [-3.8939003e+01  3.2210007e+00  6.3320000e+01]\n   [-4.1939003e+01  7.2210007e+00  6.0320000e+01]\n   ...\n   [-5.0939003e+01 -4.1778999e+01  2.2320000e+01]\n   [-3.9939003e+01 -3.0778999e+01  3.4320000e+01]\n   [-1.2939003e+01  1.6221001e+01  5.4320000e+01]]\n\n  [[-3.7939003e+01  2.2210007e+00  6.2320000e+01]\n   [-3.2939003e+01  6.2210007e+00  6.5320000e+01]\n   [-2.9939003e+01  8.2210007e+00  6.4320000e+01]\n   ...\n   [-5.8939003e+01 -6.4778999e+01 -2.6800003e+00]\n   [-1.7939003e+01  1.7221001e+01  6.2320000e+01]\n   [ 1.6060997e+01  5.0221001e+01  9.7320000e+01]]\n\n  [[-3.9939003e+01  2.2100067e-01  6.0320000e+01]\n   [-3.0939003e+01  8.2210007e+00  6.7320000e+01]\n   [-2.7939003e+01  1.0221001e+01  6.6320000e+01]\n   ...\n   [-4.7939003e+01 -6.4778999e+01  4.3199997e+00]\n   [-6.3939003e+01 -4.0778999e+01  1.6320000e+01]\n   [-1.3939003e+01  3.0221001e+01  7.5320000e+01]]]\n\n\n [[[-6.5939003e+01 -7.1778999e+01 -5.9680000e+01]\n   [-8.3939003e+01 -8.4778999e+01 -6.7680000e+01]\n   [-8.0939003e+01 -7.4778999e+01 -4.8680000e+01]\n   ...\n   [-7.9939003e+01 -6.1778999e+01 -2.3680000e+01]\n   [-8.4939003e+01 -6.6778999e+01 -2.8680000e+01]\n   [-1.0393900e+02 -1.0477900e+02 -7.7680000e+01]]\n\n  [[-8.3939003e+01 -8.2778999e+01 -6.6680000e+01]\n   [-8.6939003e+01 -8.6778999e+01 -6.7680000e+01]\n   [-8.6939003e+01 -8.5778999e+01 -6.4680000e+01]\n   ...\n   [-7.3939003e+01 -7.2778999e+01 -5.6680000e+01]\n   [-1.0393900e+02 -1.0977900e+02 -9.3680000e+01]\n   [-6.6939003e+01 -7.2778999e+01 -6.4680000e+01]]\n\n  [[-8.7939003e+01 -7.9778999e+01 -5.4680000e+01]\n   [-8.4939003e+01 -7.9778999e+01 -5.7680000e+01]\n   [-8.0939003e+01 -8.0778999e+01 -6.1680000e+01]\n   ...\n   [-1.0393900e+02 -1.1177900e+02 -1.0068000e+02]\n   [-7.0939003e+01 -7.1778999e+01 -6.0680000e+01]\n   [-8.6939003e+01 -9.8778999e+01 -9.1680000e+01]]\n\n  ...\n\n  [[-6.1939003e+01 -1.8778999e+01  4.5320000e+01]\n   [-4.7939003e+01  1.2221001e+01  7.3320000e+01]\n   [-1.0393900e+02 -6.1778999e+01  1.1320000e+01]\n   ...\n   [-9.9939003e+01 -9.7778999e+01 -7.1680000e+01]\n   [-8.7939003e+01 -9.4778999e+01 -7.8680000e+01]\n   [-9.1939003e+01 -9.4778999e+01 -9.1680000e+01]]\n\n  [[-7.6939003e+01 -1.6778999e+01  5.8320000e+01]\n   [-7.6939003e+01 -4.7789993e+00  5.8320000e+01]\n   [-4.6939003e+01 -2.9778999e+01  4.4320000e+01]\n   ...\n   [-7.3939003e+01 -7.9778999e+01 -6.6680000e+01]\n   [-8.6939003e+01 -9.6778999e+01 -7.5680000e+01]\n   [-7.8939003e+01 -8.8778999e+01 -7.4680000e+01]]\n\n  [[-5.6939003e+01  3.2210007e+00  7.8320000e+01]\n   [-5.7939003e+01  1.4221001e+01  7.7320000e+01]\n   [-9.4939003e+01 -7.7778999e+01 -3.6800003e+00]\n   ...\n   [-1.0393900e+02 -1.0677900e+02 -8.7680000e+01]\n   [-1.0393900e+02 -1.1077900e+02 -8.3680000e+01]\n   [-7.4939003e+01 -8.6778999e+01 -6.5680000e+01]]]\n\n\n [[[-7.9390030e+00 -1.5778999e+01 -2.1680000e+01]\n   [ 4.0609970e+00 -3.7789993e+00 -9.6800003e+00]\n   [ 6.0997009e-02 -7.7789993e+00 -1.3680000e+01]\n   ...\n   [-5.9939003e+01 -7.0778999e+01 -6.6680000e+01]\n   [-1.0393900e+02 -1.1677900e+02 -1.1468000e+02]\n   [-8.4939003e+01 -9.6778999e+01 -1.0568000e+02]]\n\n  [[-1.6939003e+01 -2.5778999e+01 -3.1680000e+01]\n   [-7.9390030e+00 -1.6778999e+01 -2.2680000e+01]\n   [-3.9390030e+00 -1.2778999e+01 -1.8680000e+01]\n   ...\n   [-5.7939003e+01 -6.8778999e+01 -6.5680000e+01]\n   [-4.9939003e+01 -6.1778999e+01 -5.8680000e+01]\n   [-9.0939003e+01 -1.0377900e+02 -1.1068000e+02]]\n\n  [[-1.6939003e+01 -2.7778999e+01 -3.3680000e+01]\n   [-2.6939003e+01 -3.7778999e+01 -4.3680000e+01]\n   [-1.2939003e+01 -2.3778999e+01 -2.9680000e+01]\n   ...\n   [-5.0939003e+01 -6.0778999e+01 -5.9680000e+01]\n   [-5.8939003e+01 -6.9778999e+01 -6.8680000e+01]\n   [-9.7939003e+01 -1.1177900e+02 -1.1668000e+02]]\n\n  ...\n\n  [[ 8.5060997e+01  7.4221001e+01  6.8320000e+01]\n   [ 8.0060997e+01  6.9221001e+01  6.3320000e+01]\n   [ 9.7060997e+01  8.6221001e+01  8.0320000e+01]\n   ...\n   [ 5.0609970e+00 -5.7789993e+00 -1.1680000e+01]\n   [ 3.1060997e+01  2.0221001e+01  1.4320000e+01]\n   [ 3.5060997e+01  1.6221001e+01  2.0320000e+01]]\n\n  [[ 8.6060997e+01  7.7221001e+01  7.1320000e+01]\n   [ 8.1060997e+01  7.2221001e+01  6.6320000e+01]\n   [ 8.1060997e+01  7.2221001e+01  6.6320000e+01]\n   ...\n   [-9.3900299e-01 -9.7789993e+00 -1.5680000e+01]\n   [-6.9390030e+00 -1.5778999e+01 -2.1680000e+01]\n   [-1.9390030e+00 -1.7778999e+01 -2.2680000e+01]]\n\n  [[ 9.1060997e+01  8.2221001e+01  7.6320000e+01]\n   [ 9.2060997e+01  8.3221001e+01  7.7320000e+01]\n   [ 8.7060997e+01  7.8221001e+01  7.2320000e+01]\n   ...\n   [ 2.4060997e+01  1.5221001e+01  9.3199997e+00]\n   [-1.2939003e+01 -2.1778999e+01 -2.7680000e+01]\n   [-2.9390030e+00 -1.0778999e+01 -1.6680000e+01]]]\n\n\n ...\n\n\n [[[-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   ...\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]]\n\n  [[-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   ...\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]]\n\n  [[-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   ...\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]\n   [-1.0293900e+02 -1.1577900e+02 -1.2268000e+02]]\n\n  ...\n\n  [[ 1.4306100e+02  1.2522100e+02  1.1532000e+02]\n   [ 1.4506100e+02  1.2722100e+02  1.1732000e+02]\n   [ 1.4706100e+02  1.2922101e+02  1.1932000e+02]\n   ...\n   [ 9.8060997e+01  8.2221001e+01  6.7320000e+01]\n   [ 1.0006100e+02  8.4221001e+01  6.9320000e+01]\n   [ 9.8060997e+01  8.2221001e+01  6.7320000e+01]]\n\n  [[ 1.4206100e+02  1.2422100e+02  1.1432000e+02]\n   [ 1.4706100e+02  1.2922101e+02  1.1932000e+02]\n   [ 1.4606100e+02  1.2822101e+02  1.1832000e+02]\n   ...\n   [ 9.3060997e+01  7.7221001e+01  6.2320000e+01]\n   [ 9.1060997e+01  7.5221001e+01  6.0320000e+01]\n   [ 9.7060997e+01  8.1221001e+01  6.6320000e+01]]\n\n  [[ 1.3906100e+02  1.2122100e+02  1.1132000e+02]\n   [ 1.4306100e+02  1.2522100e+02  1.1532000e+02]\n   [ 1.4406100e+02  1.2622100e+02  1.1632000e+02]\n   ...\n   [ 7.6060997e+01  5.8221001e+01  4.8320000e+01]\n   [ 9.5060997e+01  7.7221001e+01  6.7320000e+01]\n   [ 1.0006100e+02  8.2221001e+01  7.2320000e+01]]]\n\n\n [[[ 6.0060997e+01  4.7221001e+01  4.6320000e+01]\n   [ 6.1060997e+01  4.8221001e+01  4.7320000e+01]\n   [ 6.0060997e+01  4.7221001e+01  4.6320000e+01]\n   ...\n   [ 1.1060997e+01  3.2210007e+00 -2.6800003e+00]\n   [ 1.7060997e+01  9.2210007e+00  3.3199997e+00]\n   [ 2.3060997e+01  1.4221001e+01  1.2320000e+01]]\n\n  [[ 5.9060997e+01  4.6221001e+01  4.5320000e+01]\n   [ 6.6060997e+01  5.3221001e+01  5.2320000e+01]\n   [ 6.5060997e+01  5.2221001e+01  5.1320000e+01]\n   ...\n   [-1.9390030e+00 -1.0778999e+01 -1.6680000e+01]\n   [ 3.0609970e+00 -5.7789993e+00 -1.1680000e+01]\n   [ 1.3060997e+01  3.2210007e+00  1.3199997e+00]]\n\n  [[ 6.7060997e+01  5.4221001e+01  5.3320000e+01]\n   [ 6.9060997e+01  5.6221001e+01  5.5320000e+01]\n   [ 6.5060997e+01  5.2221001e+01  5.1320000e+01]\n   ...\n   [-2.9390030e+00 -1.3778999e+01 -1.9680000e+01]\n   [ 1.0609970e+00 -9.7789993e+00 -1.5680000e+01]\n   [ 6.0609970e+00 -6.7789993e+00 -7.6800003e+00]]\n\n  ...\n\n  [[ 3.0609970e+00  3.0221001e+01  7.1320000e+01]\n   [-2.6939003e+01  2.2100067e-01  4.2320000e+01]\n   [-1.0939003e+01  1.6221001e+01  6.1320000e+01]\n   ...\n   [ 1.9060997e+01 -8.7789993e+00 -1.7680000e+01]\n   [ 5.2060997e+01  2.4221001e+01  1.5320000e+01]\n   [ 2.1060997e+01  1.2210007e+00 -3.0680000e+01]]\n\n  [[-1.4939003e+01  7.2210007e+00  5.0320000e+01]\n   [ 1.1060997e+01  3.5221001e+01  8.0320000e+01]\n   [-5.9390030e+00  1.8221001e+01  6.7320000e+01]\n   ...\n   [ 9.0609970e+00 -1.7778999e+01 -2.3680000e+01]\n   [ 1.0806100e+02  8.3221001e+01  7.6320000e+01]\n   [ 8.9060997e+01  6.4221001e+01  5.5320000e+01]]\n\n  [[-6.9390030e+00  1.5221001e+01  5.8320000e+01]\n   [ 1.9060997e+01  4.3221001e+01  8.8320000e+01]\n   [-7.9390030e+00  1.6221001e+01  6.5320000e+01]\n   ...\n   [ 1.3060997e+01 -1.3778999e+01 -1.9680000e+01]\n   [ 1.4060997e+01 -1.0778999e+01 -1.7680000e+01]\n   [ 7.9060997e+01  5.2221001e+01  5.1320000e+01]]]\n\n\n [[[ 8.6060997e+01  7.1221001e+01  6.4320000e+01]\n   [ 8.7060997e+01  7.2221001e+01  6.5320000e+01]\n   [ 7.2060997e+01  5.7221001e+01  5.0320000e+01]\n   ...\n   [-2.0939003e+01 -3.4778999e+01 -3.9680000e+01]\n   [ 1.0060997e+01 -3.7789993e+00 -8.6800003e+00]\n   [-3.1939003e+01 -4.2778999e+01 -4.9680000e+01]]\n\n  [[ 9.2060997e+01  7.7221001e+01  7.0320000e+01]\n   [ 7.3060997e+01  5.8221001e+01  5.1320000e+01]\n   [ 3.8060997e+01  2.3221001e+01  1.6320000e+01]\n   ...\n   [-7.7939003e+01 -9.1778999e+01 -9.6680000e+01]\n   [-4.0939003e+01 -5.4778999e+01 -5.9680000e+01]\n   [-7.4939003e+01 -8.7778999e+01 -9.4680000e+01]]\n\n  [[ 8.0060997e+01  6.5221001e+01  5.8320000e+01]\n   [ 6.9060997e+01  5.4221001e+01  4.7320000e+01]\n   [ 6.6060997e+01  5.1221001e+01  4.4320000e+01]\n   ...\n   [ 1.6060997e+01  2.2210007e+00 -2.6800003e+00]\n   [ 2.3060997e+01  9.2210007e+00  4.3199997e+00]\n   [ 9.9060997e+01  8.4221001e+01  7.7320000e+01]]\n\n  ...\n\n  [[ 8.8060997e+01  7.5221001e+01  6.8320000e+01]\n   [ 1.0206100e+02  8.9221001e+01  8.2320000e+01]\n   [ 9.9060997e+01  8.6221001e+01  7.9320000e+01]\n   ...\n   [ 1.0806100e+02  9.5221001e+01  8.8320000e+01]\n   [ 9.9060997e+01  8.6221001e+01  7.9320000e+01]\n   [ 9.4060997e+01  8.1221001e+01  7.4320000e+01]]\n\n  [[ 9.6060997e+01  8.3221001e+01  7.6320000e+01]\n   [ 9.8060997e+01  8.5221001e+01  7.8320000e+01]\n   [ 1.0706100e+02  9.4221001e+01  8.7320000e+01]\n   ...\n   [ 1.0606100e+02  9.3221001e+01  8.6320000e+01]\n   [ 9.9060997e+01  8.6221001e+01  7.9320000e+01]\n   [ 1.0406100e+02  9.1221001e+01  8.4320000e+01]]\n\n  [[ 9.9060997e+01  8.6221001e+01  7.9320000e+01]\n   [ 1.0206100e+02  8.9221001e+01  8.2320000e+01]\n   [ 1.0006100e+02  8.7221001e+01  8.0320000e+01]\n   ...\n   [ 9.9060997e+01  8.6221001e+01  7.9320000e+01]\n   [ 1.0206100e+02  8.9221001e+01  8.2320000e+01]\n   [ 8.9060997e+01  7.6221001e+01  6.9320000e+01]]]]\n"
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "markdown",
            "source": [
                "View encoding."
            ],
            "metadata": {
                "azdata_cell_guid": "0a22d677-f51c-43fa-ac6f-16906db15379"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print(y_labels)"
            ],
            "metadata": {
                "jupyter": {
                    "outputs_hidden": true
                },
                "tags": [],
                "azdata_cell_guid": "1520c8e3-bbcf-4c30-a83b-8c05bb56985b",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "[[1. 0. 0. ... 0. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]\n [0. 0. 1. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n"
                }
            ],
            "execution_count": 13
        },
        {
            "cell_type": "markdown",
            "source": [
                "Split the data into training and testing for each model."
            ],
            "metadata": {
                "id": "G4urtH2nifts",
                "azdata_cell_guid": "09bd29f3-c6a9-456c-9ffc-222e807aaf37"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(x_labels_vgg, y_labels, test_size = 0.2, random_state=2)\n",
                "X_train1, X_test1, y_train1, y_test1 = train_test_split(x_labels_mobile, y_labels, test_size = 0.2, random_state=2)\n",
                "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_labels_dense, y_labels, test_size = 0.2, random_state=2)\n",
                "X_train3, X_test3, y_train3, y_test = train_test_split(x_labels_eff, y_labels, test_size = 0.2, random_state=2)"
            ],
            "metadata": {
                "id": "J2K8FNbhYDkz",
                "azdata_cell_guid": "02cd40f8-9f17-43cf-9809-d2cf642d38c4",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 14
        },
        {
            "cell_type": "markdown",
            "source": [
                ".Vew the first set of x arrays"
            ],
            "metadata": {
                "id": "vAhiqB1dC-Rc",
                "tags": [],
                "azdata_cell_guid": "5b372a1f-3f13-4da9-91c3-776edbf8fbe6"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print(X_train)"
            ],
            "metadata": {
                "jupyter": {
                    "outputs_hidden": true
                },
                "tags": [],
                "azdata_cell_guid": "b4462cd6-1d53-4bc0-bab1-700b30b66689",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "[[[[ -71.939       -76.779       -90.68      ]\n   [ -78.939       -84.779       -96.68      ]\n   [ -84.939       -90.779      -100.68      ]\n   ...\n   [ -76.939       -88.779       -81.68      ]\n   [ -83.939       -96.779       -91.68      ]\n   [ -79.939       -93.779       -90.68      ]]\n\n  [[ -42.939003    -47.779       -64.68      ]\n   [ -43.939003    -49.779       -63.68      ]\n   [ -30.939003    -37.779       -49.68      ]\n   ...\n   [ -86.939       -96.779       -89.68      ]\n   [ -81.939       -91.779       -84.68      ]\n   [ -79.939       -90.779       -86.68      ]]\n\n  [[  31.060997     20.221         7.3199997 ]\n   [  40.060997     29.221        16.32      ]\n   [  30.060997     18.221         7.3199997 ]\n   ...\n   [ -82.939       -86.779       -79.68      ]\n   [ -89.939       -94.779       -88.68      ]\n   [ -88.939       -95.779       -91.68      ]]\n\n  ...\n\n  [[ -98.939      -102.779      -112.68      ]\n   [ -98.939      -109.779       -98.68      ]\n   [ -98.939      -111.779      -100.68      ]\n   ...\n   [  17.060997     11.221001     23.32      ]\n   [  22.060997     16.221        28.32      ]\n   [  16.060997     12.221001     18.32      ]]\n\n  [[ -95.939       -99.779      -109.68      ]\n   [-103.939      -115.779      -104.68      ]\n   [ -95.939      -108.779       -97.68      ]\n   ...\n   [  28.060997     22.221        34.32      ]\n   [  20.060997     14.221001     26.32      ]\n   [  21.060997     17.221        23.32      ]]\n\n  [[ -94.939       -98.779      -108.68      ]\n   [-103.939      -116.779      -108.68      ]\n   [ -94.939      -107.779       -96.68      ]\n   ...\n   [  20.060997     14.221001     26.32      ]\n   [  27.060997     21.221        33.32      ]\n   [  21.060997     17.221        23.32      ]]]\n\n\n [[[ 127.061       108.221        88.32      ]\n   [ 128.061       109.221        89.32      ]\n   [ 128.061       109.221        89.32      ]\n   ...\n   [ -83.939       -95.779      -106.68      ]\n   [ -89.939      -101.779      -112.68      ]\n   [ -88.939      -100.779      -111.68      ]]\n\n  [[ 129.061       110.221        90.32      ]\n   [ 131.061       112.221        92.32      ]\n   [ 133.061       114.221        94.32      ]\n   ...\n   [ -93.939      -105.779      -116.68      ]\n   [ -82.939       -94.779      -105.68      ]\n   [ -87.939       -99.779      -110.68      ]]\n\n  [[ 133.061       114.221        94.32      ]\n   [ 133.061       114.221        94.32      ]\n   [ 133.061       114.221        94.32      ]\n   ...\n   [ -86.939       -98.779      -109.68      ]\n   [ -90.939      -102.779      -113.68      ]\n   [ -90.939      -102.779      -113.68      ]]\n\n  ...\n\n  [[ 123.061       104.221        84.32      ]\n   [ 126.061       107.221        87.32      ]\n   [ 130.061       111.221        91.32      ]\n   ...\n   [ 119.061        97.221        80.32      ]\n   [ 119.061        97.221        80.32      ]\n   [ 119.061        97.221        80.32      ]]\n\n  [[ 124.061       105.221        85.32      ]\n   [ 128.061       109.221        89.32      ]\n   [ 132.061       113.221        93.32      ]\n   ...\n   [ 119.061        97.221        80.32      ]\n   [ 119.061        97.221        80.32      ]\n   [ 119.061        97.221        80.32      ]]\n\n  [[ 128.061       109.221        89.32      ]\n   [ 130.061       111.221        91.32      ]\n   [ 130.061       111.221        91.32      ]\n   ...\n   [ 118.061        99.221        81.32      ]\n   [ 118.061        99.221        81.32      ]\n   [ 115.061        96.221        78.32      ]]]\n\n\n [[[ -47.939003    -58.779       -47.68      ]\n   [ -52.939003    -64.779       -51.68      ]\n   [ -36.939003    -49.779       -32.68      ]\n   ...\n   [ -55.939003    -60.779       -50.68      ]\n   [ -52.939003    -57.779       -47.68      ]\n   [ -47.939003    -56.779       -52.68      ]]\n\n  [[ -55.939003    -66.779       -55.68      ]\n   [ -51.939003    -63.779       -50.68      ]\n   [ -33.939003    -46.779       -29.68      ]\n   ...\n   [ -52.939003    -57.779       -47.68      ]\n   [ -52.939003    -57.779       -47.68      ]\n   [ -51.939003    -58.779       -52.68      ]]\n\n  [[ -61.939003    -72.779       -61.68      ]\n   [ -48.939003    -60.779       -47.68      ]\n   [ -29.939003    -42.779       -25.68      ]\n   ...\n   [ -55.939003    -60.779       -50.68      ]\n   [ -52.939003    -57.779       -47.68      ]\n   [ -58.939003    -62.779       -55.68      ]]\n\n  ...\n\n  [[ -90.939       -94.779       -91.68      ]\n   [ -85.939       -89.779       -86.68      ]\n   [ -84.939       -88.779       -85.68      ]\n   ...\n   [ -70.939       -74.779       -67.68      ]\n   [ -77.939       -81.779       -74.68      ]\n   [ -71.939       -73.779       -72.68      ]]\n\n  [[ -91.939       -95.779       -92.68      ]\n   [ -87.939       -91.779       -88.68      ]\n   [ -82.939       -86.779       -83.68      ]\n   ...\n   [ -80.939       -84.779       -77.68      ]\n   [ -85.939       -89.779       -82.68      ]\n   [ -79.939       -80.779       -81.68      ]]\n\n  [[ -88.939       -90.779       -93.68      ]\n   [ -87.939       -91.779       -94.68      ]\n   [ -85.939       -94.779       -96.68      ]\n   ...\n   [ -87.939       -95.779       -93.68      ]\n   [ -85.939       -93.779       -91.68      ]\n   [ -84.939       -92.779       -90.68      ]]]\n\n\n ...\n\n\n [[[ -81.939       -97.779      -102.68      ]\n   [ -81.939       -97.779      -102.68      ]\n   [ -85.939      -101.779      -106.68      ]\n   ...\n   [ -12.939003    -40.779       -49.68      ]\n   [ -16.939003    -44.779       -53.68      ]\n   [ -20.939003    -48.779       -57.68      ]]\n\n  [[ -63.939003    -90.779      -115.68      ]\n   [ -67.939       -94.779      -119.68      ]\n   [ -67.939       -94.779      -119.68      ]\n   ...\n   [ -14.939003    -42.779       -51.68      ]\n   [ -21.939003    -49.779       -58.68      ]\n   [ -18.939003    -46.779       -55.68      ]]\n\n  [[  67.061        56.221        49.32      ]\n   [  58.060997     47.221        40.32      ]\n   [  57.060997     46.221        39.32      ]\n   ...\n   [ -18.939003    -46.779       -55.68      ]\n   [ -27.939003    -55.779       -64.68      ]\n   [ -34.939003    -62.779       -71.68      ]]\n\n  ...\n\n  [[  85.061        75.221        53.32      ]\n   [  78.061        68.221        46.32      ]\n   [  72.061        62.221        40.32      ]\n   ...\n   [ -76.939       -84.779       -90.68      ]\n   [ -69.939       -77.779       -83.68      ]\n   [ -63.939003    -71.779       -77.68      ]]\n\n  [[  96.061        82.221        65.32      ]\n   [  93.061        79.221        62.32      ]\n   [  70.061        56.221        39.32      ]\n   ...\n   [ -73.939       -78.779       -85.68      ]\n   [ -65.939       -70.779       -77.68      ]\n   [ -72.939       -77.779       -84.68      ]]\n\n  [[  71.061        62.221        50.32      ]\n   [  84.061        75.221        62.32      ]\n   [  72.061        64.221        48.32      ]\n   ...\n   [ -72.939       -82.779       -84.68      ]\n   [ -65.939       -75.779       -77.68      ]\n   [ -65.939       -73.779       -82.68      ]]]\n\n\n [[[ 119.061       104.221        97.32      ]\n   [ 118.061       103.221        96.32      ]\n   [ 117.061       102.221        95.32      ]\n   ...\n   [-100.939      -103.779      -116.68      ]\n   [-100.939      -103.779      -116.68      ]\n   [-100.939      -103.779      -116.68      ]]\n\n  [[ 132.061       117.221       110.32      ]\n   [ 132.061       117.221       110.32      ]\n   [ 130.061       115.221       108.32      ]\n   ...\n   [ -85.939       -80.779       -94.68      ]\n   [ -84.939       -79.779       -93.68      ]\n   [ -83.939       -78.779       -92.68      ]]\n\n  [[ 131.061       116.221       109.32      ]\n   [ 131.061       116.221       109.32      ]\n   [ 131.061       116.221       109.32      ]\n   ...\n   [ -79.939       -69.779       -84.68      ]\n   [ -81.939       -71.779       -86.68      ]\n   [ -81.939       -71.779       -86.68      ]]\n\n  ...\n\n  [[  16.060997      8.221001      4.3199997 ]\n   [  31.060997     21.221        18.32      ]\n   [  39.060997     27.221        24.32      ]\n   ...\n   [ -61.939003    -40.779       -53.68      ]\n   [ -80.939       -45.779       -64.68      ]\n   [ -82.939       -35.779       -60.68      ]]\n\n  [[   7.060997      0.22100067   -1.6800003 ]\n   [  27.060997     18.221        16.32      ]\n   [  40.060997     30.221        28.32      ]\n   ...\n   [ -79.939       -54.779       -67.68      ]\n   [ -86.939       -53.779       -72.68      ]\n   [ -87.939       -45.779       -69.68      ]]\n\n  [[  -6.939003     -7.7789993   -14.68      ]\n   [   7.060997      2.2210007    -4.6800003 ]\n   [  36.060997     27.221        21.32      ]\n   ...\n   [ -52.939003     -3.7789993     5.3199997 ]\n   [ -60.939003    -16.779       -24.68      ]\n   [ -88.939       -42.779       -63.68      ]]]\n\n\n [[[  62.060997    104.221        88.32      ]\n   [ -93.939       -62.779       -75.68      ]\n   [ -50.939003    -26.779       -35.68      ]\n   ...\n   [ -35.939003      4.2210007   -15.68      ]\n   [ -36.939003      4.2210007   -15.68      ]\n   [ -30.939003     10.221001     -9.68      ]]\n\n  [[  47.060997     82.221        63.32      ]\n   [  -2.939003     17.221         6.3199997 ]\n   [-103.939      -102.779      -109.68      ]\n   ...\n   [ -30.939003      9.221001    -10.68      ]\n   [ -28.939003     11.221001     -8.68      ]\n   [ -24.939003     15.221001     -4.6800003 ]]\n\n  [[  56.060997     87.221        67.32      ]\n   [  56.060997     75.221        63.32      ]\n   [ 102.061       110.221       104.32      ]\n   ...\n   [ -28.939003      8.221001    -10.68      ]\n   [ -27.939003      9.221001     -9.68      ]\n   [ -25.939003     11.221001     -7.6800003 ]]\n\n  ...\n\n  [[  10.060997     87.221        21.32      ]\n   [ -61.939003      7.2210007   -51.68      ]\n   [  -9.939003     50.221        -2.6800003 ]\n   ...\n   [ -50.939003     -4.7789993   -56.68      ]\n   [ -15.939003     28.221       -23.68      ]\n   [ -65.939       -25.779       -75.68      ]]\n\n  [[ -26.939003     46.221       -14.68      ]\n   [ -53.939003     -3.7789993   -54.68      ]\n   [  -1.939003     32.221       -13.68      ]\n   ...\n   [ -99.939       -49.779       -98.68      ]\n   [ -47.939003     -2.7789993   -50.68      ]\n   [ -63.939003    -22.779       -72.68      ]]\n\n  [[ -40.939003      9.221001    -41.68      ]\n   [ -38.939003      4.2210007   -45.68      ]\n   [ -24.939003     15.221001    -34.68      ]\n   ...\n   [ -61.939003    -24.779       -71.68      ]\n   [ -42.939003    -10.778999    -56.68      ]\n   [ -56.939003    -28.779       -72.68      ]]]]\n"
                }
            ],
            "execution_count": 15
        },
        {
            "cell_type": "markdown",
            "source": [
                "View the one-hot encoded y labels."
            ],
            "metadata": {
                "id": "1pIM57ExDEIc",
                "azdata_cell_guid": "9f91b47a-2a96-476a-b774-9637c33b6da6"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print(y_train)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 8,
                    "status": "ok",
                    "timestamp": 1680056408050,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "Y7aQQIUSdAN3",
                "jupyter": {
                    "outputs_hidden": true
                },
                "outputId": "0bb55d6a-6ac9-4de2-fec0-8ddf53f47811",
                "tags": [],
                "azdata_cell_guid": "43d97cf1-777c-4148-a7a6-cafd7c8d987d",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "[[0. 0. 0. ... 1. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 1. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n"
                }
            ],
            "execution_count": 16
        },
        {
            "cell_type": "markdown",
            "source": [
                "Create an earlystopping object for all models. This method stops training the model if the accuracy stays consistent for two iterations."
            ],
            "metadata": {
                "id": "fjshPgjDDILG",
                "azdata_cell_guid": "83766c0e-0bf8-459d-8e22-8f7415fb3d92"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "earlystop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=2)"
            ],
            "metadata": {
                "id": "I2lDmAOK2LpK",
                "azdata_cell_guid": "63799812-36a0-4894-9b3e-4f4d19ac8d1a",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 17
        },
        {
            "cell_type": "markdown",
            "source": [
                "VGG16 model creation with an extra pooling layer, flatten layer, and dense layer."
            ],
            "metadata": {
                "id": "XG1Ohlk7DQhA",
                "azdata_cell_guid": "730a7366-588b-4d4b-a3a0-f0429deda794"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "m1=tf.keras.applications.vgg16.VGG16(weights= 'imagenet',include_top=False, input_shape=(128, 128, 3))\n",
                "m1.trainable = False\n",
                "\n",
                "x = m1.output\n",
                "x = AveragePooling2D()(x)\n",
                "x = Flatten()(x)\n",
                "x = Dropout(.2)(x)\n",
                "x = Dense(120, activation='softmax')(x)\n",
                "m1_model = Model(inputs=m1.input, outputs=x)\n",
                "m1_model.summary()"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 2193,
                    "status": "ok",
                    "timestamp": 1680050700825,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "gZa6_awLkxJo",
                "jupyter": {
                    "outputs_hidden": true
                },
                "outputId": "7b1bc734-1d98-41ea-d507-3f8f778f66b8",
                "scrolled": true,
                "tags": [],
                "azdata_cell_guid": "7726ee90-144a-4361-ac9e-043f530163de",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n                                                                 \n average_pooling2d (AverageP  (None, 2, 2, 512)        0         \n ooling2D)                                                       \n                                                                 \n flatten (Flatten)           (None, 2048)              0         \n                                                                 \n dropout (Dropout)           (None, 2048)              0         \n                                                                 \n dense (Dense)               (None, 120)               245880    \n                                                                 \n=================================================================\nTotal params: 14,960,568\nTrainable params: 245,880\nNon-trainable params: 14,714,688\n_________________________________________________________________\n"
                }
            ],
            "execution_count": 18
        },
        {
            "cell_type": "code",
            "source": [
                "m1_model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
            ],
            "metadata": {
                "id": "2GXKlp3S9mSM",
                "azdata_cell_guid": "4338488f-ca4b-4243-924e-86fab92e34bc",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 19
        },
        {
            "cell_type": "code",
            "source": [
                "m1_model.fit(X_train, y_train, epochs=20, batch_size=32, callbacks=[earlystop], validation_data = (X_test, y_test))"
            ],
            "metadata": {
                "id": "v5PcYFGQ9Vrm",
                "jupyter": {
                    "outputs_hidden": true
                },
                "scrolled": false,
                "tags": [],
                "azdata_cell_guid": "508a8591-b515-45af-91ac-0de0b9931e18",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Epoch 1/20\n256/256 [==============================] - 437s 2s/step - loss: 28.3049 - accuracy: 0.1696 - val_loss: 16.7041 - val_accuracy: 0.3193\nEpoch 2/20\n256/256 [==============================] - 430s 2s/step - loss: 11.3446 - accuracy: 0.4586 - val_loss: 15.7506 - val_accuracy: 0.3682\nEpoch 3/20\n256/256 [==============================] - 387s 2s/step - loss: 6.4634 - accuracy: 0.6167 - val_loss: 16.0906 - val_accuracy: 0.3902\nEpoch 4/20\n256/256 [==============================] - 403s 2s/step - loss: 4.2042 - accuracy: 0.7069 - val_loss: 16.8168 - val_accuracy: 0.3995\nEpoch 5/20\n256/256 [==============================] - 375s 1s/step - loss: 3.2029 - accuracy: 0.7642 - val_loss: 17.1240 - val_accuracy: 0.3936\nEpoch 6/20\n256/256 [==============================] - 397s 2s/step - loss: 2.4590 - accuracy: 0.8104 - val_loss: 17.4172 - val_accuracy: 0.4039\nEpoch 7/20\n256/256 [==============================] - 416s 2s/step - loss: 1.9330 - accuracy: 0.8433 - val_loss: 17.9900 - val_accuracy: 0.4083\nEpoch 8/20\n256/256 [==============================] - 417s 2s/step - loss: 1.6594 - accuracy: 0.8628 - val_loss: 19.6745 - val_accuracy: 0.4059\nEpoch 9/20\n256/256 [==============================] - 418s 2s/step - loss: 1.7661 - accuracy: 0.8635 - val_loss: 19.9945 - val_accuracy: 0.4240\nEpoch 10/20\n256/256 [==============================] - 394s 2s/step - loss: 1.3433 - accuracy: 0.8912 - val_loss: 20.5516 - val_accuracy: 0.4117\nEpoch 11/20\n256/256 [==============================] - 363s 1s/step - loss: 1.5270 - accuracy: 0.8839 - val_loss: 21.6584 - val_accuracy: 0.4020\nEpoch 12/20\n256/256 [==============================] - 362s 1s/step - loss: 1.3186 - accuracy: 0.8983 - val_loss: 21.4195 - val_accuracy: 0.4171\nEpoch 13/20\n256/256 [==============================] - 370s 1s/step - loss: 1.2641 - accuracy: 0.9057 - val_loss: 22.6883 - val_accuracy: 0.4249\nEpoch 14/20\n256/256 [==============================] - 365s 1s/step - loss: 1.4874 - accuracy: 0.8974 - val_loss: 23.4943 - val_accuracy: 0.4093\nEpoch 15/20\n256/256 [==============================] - 363s 1s/step - loss: 1.3591 - accuracy: 0.9078 - val_loss: 25.6263 - val_accuracy: 0.3966\nEpoch 16/20\n256/256 [==============================] - 363s 1s/step - loss: 1.3351 - accuracy: 0.9080 - val_loss: 25.5702 - val_accuracy: 0.4117\nEpoch 17/20\n256/256 [==============================] - 369s 1s/step - loss: 1.2054 - accuracy: 0.9205 - val_loss: 26.6217 - val_accuracy: 0.4098\nEpoch 18/20\n256/256 [==============================] - 358s 1s/step - loss: 1.0752 - accuracy: 0.9280 - val_loss: 25.1881 - val_accuracy: 0.4186\nEpoch 19/20\n256/256 [==============================] - 362s 1s/step - loss: 1.2258 - accuracy: 0.9247 - val_loss: 27.5095 - val_accuracy: 0.4191\nEpoch 20/20\n256/256 [==============================] - 361s 1s/step - loss: 1.2462 - accuracy: 0.9214 - val_loss: 27.0839 - val_accuracy: 0.4240\n"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 20,
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x25c017b17e0>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 20
        },
        {
            "cell_type": "markdown",
            "source": [
                "MobileNet model creation with an extra pooling layer, flatten layer, and dense layer."
            ],
            "metadata": {
                "id": "oFP6vex9DcVp",
                "azdata_cell_guid": "cefe90e9-8ca1-482a-a4c0-ce42eac717d1"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "m2=tf.keras.applications.mobilenet.MobileNet(weights= 'imagenet',include_top=False, input_shape=(128, 128, 3))\n",
                "m2.trainable = False\n",
                "\n",
                "x = m2.output\n",
                "x = AveragePooling2D()(x)\n",
                "x = Flatten()(x)\n",
                "x = Dropout(.2)(x)\n",
                "x = Dense(120, activation='softmax')(x)\n",
                "m2_model = Model(inputs=m2.input, outputs=x)\n",
                "m2_model.summary()"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 2200,
                    "status": "ok",
                    "timestamp": 1680047274148,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "RETzevhy4GIl",
                "jupyter": {
                    "outputs_hidden": true
                },
                "outputId": "de34710b-ee09-4904-adf2-ccefdd15f2d3",
                "scrolled": true,
                "tags": [],
                "azdata_cell_guid": "78c2bdcf-9eeb-442f-b6c1-c3c897295724",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Model: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n                                                                 \n conv1 (Conv2D)              (None, 64, 64, 32)        864       \n                                                                 \n conv1_bn (BatchNormalizatio  (None, 64, 64, 32)       128       \n n)                                                              \n                                                                 \n conv1_relu (ReLU)           (None, 64, 64, 32)        0         \n                                                                 \n conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)       288       \n                                                                 \n conv_dw_1_bn (BatchNormaliz  (None, 64, 64, 32)       128       \n ation)                                                          \n                                                                 \n conv_dw_1_relu (ReLU)       (None, 64, 64, 32)        0         \n                                                                 \n conv_pw_1 (Conv2D)          (None, 64, 64, 64)        2048      \n                                                                 \n conv_pw_1_bn (BatchNormaliz  (None, 64, 64, 64)       256       \n ation)                                                          \n                                                                 \n conv_pw_1_relu (ReLU)       (None, 64, 64, 64)        0         \n                                                                 \n conv_pad_2 (ZeroPadding2D)  (None, 65, 65, 64)        0         \n                                                                 \n conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)       576       \n                                                                 \n conv_dw_2_bn (BatchNormaliz  (None, 32, 32, 64)       256       \n ation)                                                          \n                                                                 \n conv_dw_2_relu (ReLU)       (None, 32, 32, 64)        0         \n                                                                 \n conv_pw_2 (Conv2D)          (None, 32, 32, 128)       8192      \n                                                                 \n conv_pw_2_bn (BatchNormaliz  (None, 32, 32, 128)      512       \n ation)                                                          \n                                                                 \n conv_pw_2_relu (ReLU)       (None, 32, 32, 128)       0         \n                                                                 \n conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)      1152      \n                                                                 \n conv_dw_3_bn (BatchNormaliz  (None, 32, 32, 128)      512       \n ation)                                                          \n                                                                 \n conv_dw_3_relu (ReLU)       (None, 32, 32, 128)       0         \n                                                                 \n conv_pw_3 (Conv2D)          (None, 32, 32, 128)       16384     \n                                                                 \n conv_pw_3_bn (BatchNormaliz  (None, 32, 32, 128)      512       \n ation)                                                          \n                                                                 \n conv_pw_3_relu (ReLU)       (None, 32, 32, 128)       0         \n                                                                 \n conv_pad_4 (ZeroPadding2D)  (None, 33, 33, 128)       0         \n                                                                 \n conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)      1152      \n                                                                 \n conv_dw_4_bn (BatchNormaliz  (None, 16, 16, 128)      512       \n ation)                                                          \n                                                                 \n conv_dw_4_relu (ReLU)       (None, 16, 16, 128)       0         \n                                                                 \n conv_pw_4 (Conv2D)          (None, 16, 16, 256)       32768     \n                                                                 \n conv_pw_4_bn (BatchNormaliz  (None, 16, 16, 256)      1024      \n ation)                                                          \n                                                                 \n conv_pw_4_relu (ReLU)       (None, 16, 16, 256)       0         \n                                                                 \n conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)      2304      \n                                                                 \n conv_dw_5_bn (BatchNormaliz  (None, 16, 16, 256)      1024      \n ation)                                                          \n                                                                 \n conv_dw_5_relu (ReLU)       (None, 16, 16, 256)       0         \n                                                                 \n conv_pw_5 (Conv2D)          (None, 16, 16, 256)       65536     \n                                                                 \n conv_pw_5_bn (BatchNormaliz  (None, 16, 16, 256)      1024      \n ation)                                                          \n                                                                 \n conv_pw_5_relu (ReLU)       (None, 16, 16, 256)       0         \n                                                                 \n conv_pad_6 (ZeroPadding2D)  (None, 17, 17, 256)       0         \n                                                                 \n conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)        2304      \n                                                                 \n conv_dw_6_bn (BatchNormaliz  (None, 8, 8, 256)        1024      \n ation)                                                          \n                                                                 \n conv_dw_6_relu (ReLU)       (None, 8, 8, 256)         0         \n                                                                 \n conv_pw_6 (Conv2D)          (None, 8, 8, 512)         131072    \n                                                                 \n conv_pw_6_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n ation)                                                          \n                                                                 \n conv_pw_6_relu (ReLU)       (None, 8, 8, 512)         0         \n                                                                 \n conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)        4608      \n                                                                 \n conv_dw_7_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n ation)                                                          \n                                                                 \n conv_dw_7_relu (ReLU)       (None, 8, 8, 512)         0         \n                                                                 \n conv_pw_7 (Conv2D)          (None, 8, 8, 512)         262144    \n                                                                 \n conv_pw_7_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n ation)                                                          \n                                                                 \n conv_pw_7_relu (ReLU)       (None, 8, 8, 512)         0         \n                                                                 \n conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)        4608      \n                                                                 \n conv_dw_8_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n ation)                                                          \n                                                                 \n conv_dw_8_relu (ReLU)       (None, 8, 8, 512)         0         \n                                                                 \n conv_pw_8 (Conv2D)          (None, 8, 8, 512)         262144    \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "                                                                 \n conv_pw_8_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n ation)                                                          \n                                                                 \n conv_pw_8_relu (ReLU)       (None, 8, 8, 512)         0         \n                                                                 \n conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)        4608      \n                                                                 \n conv_dw_9_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n ation)                                                          \n                                                                 \n conv_dw_9_relu (ReLU)       (None, 8, 8, 512)         0         \n                                                                 \n conv_pw_9 (Conv2D)          (None, 8, 8, 512)         262144    \n                                                                 \n conv_pw_9_bn (BatchNormaliz  (None, 8, 8, 512)        2048      \n ation)                                                          \n                                                                 \n conv_pw_9_relu (ReLU)       (None, 8, 8, 512)         0         \n                                                                 \n conv_dw_10 (DepthwiseConv2D  (None, 8, 8, 512)        4608      \n )                                                               \n                                                                 \n conv_dw_10_bn (BatchNormali  (None, 8, 8, 512)        2048      \n zation)                                                         \n                                                                 \n conv_dw_10_relu (ReLU)      (None, 8, 8, 512)         0         \n                                                                 \n conv_pw_10 (Conv2D)         (None, 8, 8, 512)         262144    \n                                                                 \n conv_pw_10_bn (BatchNormali  (None, 8, 8, 512)        2048      \n zation)                                                         \n                                                                 \n conv_pw_10_relu (ReLU)      (None, 8, 8, 512)         0         \n                                                                 \n conv_dw_11 (DepthwiseConv2D  (None, 8, 8, 512)        4608      \n )                                                               \n                                                                 \n conv_dw_11_bn (BatchNormali  (None, 8, 8, 512)        2048      \n zation)                                                         \n                                                                 \n conv_dw_11_relu (ReLU)      (None, 8, 8, 512)         0         \n                                                                 \n conv_pw_11 (Conv2D)         (None, 8, 8, 512)         262144    \n                                                                 \n conv_pw_11_bn (BatchNormali  (None, 8, 8, 512)        2048      \n zation)                                                         \n                                                                 \n conv_pw_11_relu (ReLU)      (None, 8, 8, 512)         0         \n                                                                 \n conv_pad_12 (ZeroPadding2D)  (None, 9, 9, 512)        0         \n                                                                 \n conv_dw_12 (DepthwiseConv2D  (None, 4, 4, 512)        4608      \n )                                                               \n                                                                 \n conv_dw_12_bn (BatchNormali  (None, 4, 4, 512)        2048      \n zation)                                                         \n                                                                 \n conv_dw_12_relu (ReLU)      (None, 4, 4, 512)         0         \n                                                                 \n conv_pw_12 (Conv2D)         (None, 4, 4, 1024)        524288    \n                                                                 \n conv_pw_12_bn (BatchNormali  (None, 4, 4, 1024)       4096      \n zation)                                                         \n                                                                 \n conv_pw_12_relu (ReLU)      (None, 4, 4, 1024)        0         \n                                                                 \n conv_dw_13 (DepthwiseConv2D  (None, 4, 4, 1024)       9216      \n )                                                               \n                                                                 \n conv_dw_13_bn (BatchNormali  (None, 4, 4, 1024)       4096      \n zation)                                                         \n                                                                 \n conv_dw_13_relu (ReLU)      (None, 4, 4, 1024)        0         \n                                                                 \n conv_pw_13 (Conv2D)         (None, 4, 4, 1024)        1048576   \n                                                                 \n conv_pw_13_bn (BatchNormali  (None, 4, 4, 1024)       4096      \n zation)                                                         \n                                                                 \n conv_pw_13_relu (ReLU)      (None, 4, 4, 1024)        0         \n                                                                 \n average_pooling2d_1 (Averag  (None, 2, 2, 1024)       0         \n ePooling2D)                                                     \n                                                                 \n flatten_1 (Flatten)         (None, 4096)              0         \n                                                                 \n dropout_1 (Dropout)         (None, 4096)              0         \n                                                                 \n dense_1 (Dense)             (None, 120)               491640    \n                                                                 \n=================================================================\nTotal params: 3,720,504\nTrainable params: 491,640\nNon-trainable params: 3,228,864\n_________________________________________________________________\n"
                }
            ],
            "execution_count": 21
        },
        {
            "cell_type": "code",
            "source": [
                "m2_model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
            ],
            "metadata": {
                "id": "9NExpuhn4jOB",
                "azdata_cell_guid": "46820b86-0b76-4d8c-b753-63f54206f679",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 22
        },
        {
            "cell_type": "code",
            "source": [
                "m2_model.fit(X_train, y_train, epochs=20, batch_size=32,callbacks=[earlystop], validation_data = (X_test, y_test))"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 1000
                },
                "executionInfo": {
                    "elapsed": 90892,
                    "status": "error",
                    "timestamp": 1680050662510,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "uBdrTs_Y4n72",
                "jupyter": {
                    "outputs_hidden": true
                },
                "outputId": "7225abdb-5a12-4e5c-cfff-90afb0837d65",
                "tags": [],
                "azdata_cell_guid": "e1d746a9-fa45-411a-8a1d-1652b7a93696",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Epoch 1/20\n256/256 [==============================] - 66s 246ms/step - loss: 5.7322 - accuracy: 0.0781 - val_loss: 4.9091 - val_accuracy: 0.1193\nEpoch 2/20\n256/256 [==============================] - 60s 235ms/step - loss: 2.2628 - accuracy: 0.4554 - val_loss: 4.9416 - val_accuracy: 0.1374\nEpoch 3/20\n256/256 [==============================] - 59s 230ms/step - loss: 1.0486 - accuracy: 0.7096 - val_loss: 5.0365 - val_accuracy: 0.1384\nEpoch 4/20\n256/256 [==============================] - 58s 226ms/step - loss: 0.4989 - accuracy: 0.8660 - val_loss: 5.1575 - val_accuracy: 0.1399\nEpoch 5/20\n256/256 [==============================] - 59s 230ms/step - loss: 0.2684 - accuracy: 0.9324 - val_loss: 5.1541 - val_accuracy: 0.1526\nEpoch 6/20\n256/256 [==============================] - 57s 223ms/step - loss: 0.1738 - accuracy: 0.9617 - val_loss: 5.3027 - val_accuracy: 0.1535\nEpoch 7/20\n256/256 [==============================] - 57s 222ms/step - loss: 0.1449 - accuracy: 0.9695 - val_loss: 5.4171 - val_accuracy: 0.1320\nEpoch 8/20\n256/256 [==============================] - 57s 222ms/step - loss: 0.1241 - accuracy: 0.9716 - val_loss: 5.6287 - val_accuracy: 0.1457\nEpoch 9/20\n256/256 [==============================] - 57s 222ms/step - loss: 0.1046 - accuracy: 0.9808 - val_loss: 5.7576 - val_accuracy: 0.1403\nEpoch 10/20\n256/256 [==============================] - 57s 222ms/step - loss: 0.1080 - accuracy: 0.9771 - val_loss: 5.9906 - val_accuracy: 0.1408\nEpoch 11/20\n256/256 [==============================] - 57s 222ms/step - loss: 0.1305 - accuracy: 0.9648 - val_loss: 6.3179 - val_accuracy: 0.1477\n"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 23,
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x25c01d81540>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 23
        },
        {
            "cell_type": "markdown",
            "source": [
                "DenseNet model creation with an extra pooling layer, flatten layer, and dense layer."
            ],
            "metadata": {
                "id": "yFJe8rSRDiXR",
                "azdata_cell_guid": "cbc25e35-dc43-44de-819c-26c018da8f99"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "m3=tf.keras.applications.densenet.DenseNet121(weights='imagenet',include_top=False, input_shape=(128, 128, 3))\n",
                "m3.trainable = False\n",
                "\n",
                "x = m3.output\n",
                "x = AveragePooling2D()(x)\n",
                "x = Flatten()(x)\n",
                "x = Dropout(.2)(x)\n",
                "x = Dense(120, activation='softmax')(x)\n",
                "m3_model = Model(inputs=m3.input, outputs=x)\n",
                "m3_model.summary()"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 5518,
                    "status": "ok",
                    "timestamp": 1680072943908,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "G0Tin37b5GNd",
                "jupyter": {
                    "outputs_hidden": true
                },
                "outputId": "2d7d55bf-c9d3-4d93-bdf5-708808c597de",
                "tags": [],
                "azdata_cell_guid": "7bd4950b-916a-4523-bd83-ec7692740c7d",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Model: \"model_2\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n zero_padding2d (ZeroPadding2D)  (None, 134, 134, 3)  0          ['input_3[0][0]']                \n                                                                                                  \n conv1/conv (Conv2D)            (None, 64, 64, 64)   9408        ['zero_padding2d[0][0]']         \n                                                                                                  \n conv1/bn (BatchNormalization)  (None, 64, 64, 64)   256         ['conv1/conv[0][0]']             \n                                                                                                  \n conv1/relu (Activation)        (None, 64, 64, 64)   0           ['conv1/bn[0][0]']               \n                                                                                                  \n zero_padding2d_1 (ZeroPadding2  (None, 66, 66, 64)  0           ['conv1/relu[0][0]']             \n D)                                                                                               \n                                                                                                  \n pool1 (MaxPooling2D)           (None, 32, 32, 64)   0           ['zero_padding2d_1[0][0]']       \n                                                                                                  \n conv2_block1_0_bn (BatchNormal  (None, 32, 32, 64)  256         ['pool1[0][0]']                  \n ization)                                                                                         \n                                                                                                  \n conv2_block1_0_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block1_1_conv (Conv2D)   (None, 32, 32, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n                                                                                                  \n conv2_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block1_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n                                                                                                  \n conv2_block1_concat (Concatena  (None, 32, 32, 96)  0           ['pool1[0][0]',                  \n te)                                                              'conv2_block1_2_conv[0][0]']    \n                                                                                                  \n conv2_block2_0_bn (BatchNormal  (None, 32, 32, 96)  384         ['conv2_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block2_0_relu (Activatio  (None, 32, 32, 96)  0           ['conv2_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block2_1_conv (Conv2D)   (None, 32, 32, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n                                                                                                  \n conv2_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block2_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n                                                                                                  \n conv2_block2_concat (Concatena  (None, 32, 32, 128)  0          ['conv2_block1_concat[0][0]',    \n te)                                                              'conv2_block2_2_conv[0][0]']    \n                                                                                                  \n conv2_block3_0_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block3_0_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block3_1_conv (Conv2D)   (None, 32, 32, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n                                                                                                  \n conv2_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block3_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n                                                                                                  \n conv2_block3_concat (Concatena  (None, 32, 32, 160)  0          ['conv2_block2_concat[0][0]',    \n te)                                                              'conv2_block3_2_conv[0][0]']    \n                                                                                                  \n conv2_block4_0_bn (BatchNormal  (None, 32, 32, 160)  640        ['conv2_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block4_0_relu (Activatio  (None, 32, 32, 160)  0          ['conv2_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block4_1_conv (Conv2D)   (None, 32, 32, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "                                                                                                  \n conv2_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block4_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n                                                                                                  \n conv2_block4_concat (Concatena  (None, 32, 32, 192)  0          ['conv2_block3_concat[0][0]',    \n te)                                                              'conv2_block4_2_conv[0][0]']    \n                                                                                                  \n conv2_block5_0_bn (BatchNormal  (None, 32, 32, 192)  768        ['conv2_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block5_0_relu (Activatio  (None, 32, 32, 192)  0          ['conv2_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block5_1_conv (Conv2D)   (None, 32, 32, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n                                                                                                  \n conv2_block5_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block5_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block5_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n                                                                                                  \n conv2_block5_concat (Concatena  (None, 32, 32, 224)  0          ['conv2_block4_concat[0][0]',    \n te)                                                              'conv2_block5_2_conv[0][0]']    \n                                                                                                  \n conv2_block6_0_bn (BatchNormal  (None, 32, 32, 224)  896        ['conv2_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block6_0_relu (Activatio  (None, 32, 32, 224)  0          ['conv2_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block6_1_conv (Conv2D)   (None, 32, 32, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n                                                                                                  \n conv2_block6_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block6_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block6_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n                                                                                                  \n conv2_block6_concat (Concatena  (None, 32, 32, 256)  0          ['conv2_block5_concat[0][0]',    \n te)                                                              'conv2_block6_2_conv[0][0]']    \n                                                                                                  \n pool2_bn (BatchNormalization)  (None, 32, 32, 256)  1024        ['conv2_block6_concat[0][0]']    \n                                                                                                  \n pool2_relu (Activation)        (None, 32, 32, 256)  0           ['pool2_bn[0][0]']               \n                                                                                                  \n pool2_conv (Conv2D)            (None, 32, 32, 128)  32768       ['pool2_relu[0][0]']             \n                                                                                                  \n pool2_pool (AveragePooling2D)  (None, 16, 16, 128)  0           ['pool2_conv[0][0]']             \n                                                                                                  \n conv3_block1_0_bn (BatchNormal  (None, 16, 16, 128)  512        ['pool2_pool[0][0]']             \n ization)                                                                                         \n                                                                                                  \n conv3_block1_0_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block1_1_conv (Conv2D)   (None, 16, 16, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n                                                                                                  \n conv3_block1_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block1_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n                                                                                                  \n conv3_block1_concat (Concatena  (None, 16, 16, 160)  0          ['pool2_pool[0][0]',             \n te)                                                              'conv3_block1_2_conv[0][0]']    \n                                                                                                  \n conv3_block2_0_bn (BatchNormal  (None, 16, 16, 160)  640        ['conv3_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_0_relu (Activatio  (None, 16, 16, 160)  0          ['conv3_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " conv3_block2_1_conv (Conv2D)   (None, 16, 16, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n                                                                                                  \n conv3_block2_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block2_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n                                                                                                  \n conv3_block2_concat (Concatena  (None, 16, 16, 192)  0          ['conv3_block1_concat[0][0]',    \n te)                                                              'conv3_block2_2_conv[0][0]']    \n                                                                                                  \n conv3_block3_0_bn (BatchNormal  (None, 16, 16, 192)  768        ['conv3_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_0_relu (Activatio  (None, 16, 16, 192)  0          ['conv3_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block3_1_conv (Conv2D)   (None, 16, 16, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n                                                                                                  \n conv3_block3_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block3_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n                                                                                                  \n conv3_block3_concat (Concatena  (None, 16, 16, 224)  0          ['conv3_block2_concat[0][0]',    \n te)                                                              'conv3_block3_2_conv[0][0]']    \n                                                                                                  \n conv3_block4_0_bn (BatchNormal  (None, 16, 16, 224)  896        ['conv3_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_0_relu (Activatio  (None, 16, 16, 224)  0          ['conv3_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block4_1_conv (Conv2D)   (None, 16, 16, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n                                                                                                  \n conv3_block4_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block4_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n                                                                                                  \n conv3_block4_concat (Concatena  (None, 16, 16, 256)  0          ['conv3_block3_concat[0][0]',    \n te)                                                              'conv3_block4_2_conv[0][0]']    \n                                                                                                  \n conv3_block5_0_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv3_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block5_0_relu (Activatio  (None, 16, 16, 256)  0          ['conv3_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block5_1_conv (Conv2D)   (None, 16, 16, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n                                                                                                  \n conv3_block5_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block5_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block5_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n                                                                                                  \n conv3_block5_concat (Concatena  (None, 16, 16, 288)  0          ['conv3_block4_concat[0][0]',    \n te)                                                              'conv3_block5_2_conv[0][0]']    \n                                                                                                  \n conv3_block6_0_bn (BatchNormal  (None, 16, 16, 288)  1152       ['conv3_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block6_0_relu (Activatio  (None, 16, 16, 288)  0          ['conv3_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block6_1_conv (Conv2D)   (None, 16, 16, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n                                                                                                  \n conv3_block6_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block6_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block6_1_bn[0][0]']      \n n)                                                                                               \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "                                                                                                  \n conv3_block6_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n                                                                                                  \n conv3_block6_concat (Concatena  (None, 16, 16, 320)  0          ['conv3_block5_concat[0][0]',    \n te)                                                              'conv3_block6_2_conv[0][0]']    \n                                                                                                  \n conv3_block7_0_bn (BatchNormal  (None, 16, 16, 320)  1280       ['conv3_block6_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block7_0_relu (Activatio  (None, 16, 16, 320)  0          ['conv3_block7_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block7_1_conv (Conv2D)   (None, 16, 16, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n                                                                                                  \n conv3_block7_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block7_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block7_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block7_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block7_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n                                                                                                  \n conv3_block7_concat (Concatena  (None, 16, 16, 352)  0          ['conv3_block6_concat[0][0]',    \n te)                                                              'conv3_block7_2_conv[0][0]']    \n                                                                                                  \n conv3_block8_0_bn (BatchNormal  (None, 16, 16, 352)  1408       ['conv3_block7_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block8_0_relu (Activatio  (None, 16, 16, 352)  0          ['conv3_block8_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block8_1_conv (Conv2D)   (None, 16, 16, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n                                                                                                  \n conv3_block8_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block8_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block8_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block8_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block8_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n                                                                                                  \n conv3_block8_concat (Concatena  (None, 16, 16, 384)  0          ['conv3_block7_concat[0][0]',    \n te)                                                              'conv3_block8_2_conv[0][0]']    \n                                                                                                  \n conv3_block9_0_bn (BatchNormal  (None, 16, 16, 384)  1536       ['conv3_block8_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block9_0_relu (Activatio  (None, 16, 16, 384)  0          ['conv3_block9_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block9_1_conv (Conv2D)   (None, 16, 16, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n                                                                                                  \n conv3_block9_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block9_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block9_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block9_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block9_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n                                                                                                  \n conv3_block9_concat (Concatena  (None, 16, 16, 416)  0          ['conv3_block8_concat[0][0]',    \n te)                                                              'conv3_block9_2_conv[0][0]']    \n                                                                                                  \n conv3_block10_0_bn (BatchNorma  (None, 16, 16, 416)  1664       ['conv3_block9_concat[0][0]']    \n lization)                                                                                        \n                                                                                                  \n conv3_block10_0_relu (Activati  (None, 16, 16, 416)  0          ['conv3_block10_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block10_1_conv (Conv2D)  (None, 16, 16, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n                                                                                                  \n conv3_block10_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv3_block10_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block10_1_relu (Activati  (None, 16, 16, 128)  0          ['conv3_block10_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block10_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n                                                                                                  \n conv3_block10_concat (Concaten  (None, 16, 16, 448)  0          ['conv3_block9_concat[0][0]',    \n ate)                                                             'conv3_block10_2_conv[0][0]']   \n                                                                                                  \n conv3_block11_0_bn (BatchNorma  (None, 16, 16, 448)  1792       ['conv3_block10_concat[0][0]']   \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " lization)                                                                                        \n                                                                                                  \n conv3_block11_0_relu (Activati  (None, 16, 16, 448)  0          ['conv3_block11_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block11_1_conv (Conv2D)  (None, 16, 16, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n                                                                                                  \n conv3_block11_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv3_block11_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block11_1_relu (Activati  (None, 16, 16, 128)  0          ['conv3_block11_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block11_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n                                                                                                  \n conv3_block11_concat (Concaten  (None, 16, 16, 480)  0          ['conv3_block10_concat[0][0]',   \n ate)                                                             'conv3_block11_2_conv[0][0]']   \n                                                                                                  \n conv3_block12_0_bn (BatchNorma  (None, 16, 16, 480)  1920       ['conv3_block11_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block12_0_relu (Activati  (None, 16, 16, 480)  0          ['conv3_block12_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block12_1_conv (Conv2D)  (None, 16, 16, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n                                                                                                  \n conv3_block12_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv3_block12_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block12_1_relu (Activati  (None, 16, 16, 128)  0          ['conv3_block12_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block12_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n                                                                                                  \n conv3_block12_concat (Concaten  (None, 16, 16, 512)  0          ['conv3_block11_concat[0][0]',   \n ate)                                                             'conv3_block12_2_conv[0][0]']   \n                                                                                                  \n pool3_bn (BatchNormalization)  (None, 16, 16, 512)  2048        ['conv3_block12_concat[0][0]']   \n                                                                                                  \n pool3_relu (Activation)        (None, 16, 16, 512)  0           ['pool3_bn[0][0]']               \n                                                                                                  \n pool3_conv (Conv2D)            (None, 16, 16, 256)  131072      ['pool3_relu[0][0]']             \n                                                                                                  \n pool3_pool (AveragePooling2D)  (None, 8, 8, 256)    0           ['pool3_conv[0][0]']             \n                                                                                                  \n conv4_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['pool3_pool[0][0]']             \n ization)                                                                                         \n                                                                                                  \n conv4_block1_0_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block1_1_conv (Conv2D)   (None, 8, 8, 128)    32768       ['conv4_block1_0_relu[0][0]']    \n                                                                                                  \n conv4_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block1_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block1_1_relu[0][0]']    \n                                                                                                  \n conv4_block1_concat (Concatena  (None, 8, 8, 288)   0           ['pool3_pool[0][0]',             \n te)                                                              'conv4_block1_2_conv[0][0]']    \n                                                                                                  \n conv4_block2_0_bn (BatchNormal  (None, 8, 8, 288)   1152        ['conv4_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_0_relu (Activatio  (None, 8, 8, 288)   0           ['conv4_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block2_1_conv (Conv2D)   (None, 8, 8, 128)    36864       ['conv4_block2_0_relu[0][0]']    \n                                                                                                  \n conv4_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block2_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block2_1_relu[0][0]']    \n                                                                                                  \n conv4_block2_concat (Concatena  (None, 8, 8, 320)   0           ['conv4_block1_concat[0][0]',    \n te)                                                              'conv4_block2_2_conv[0][0]']    \n                                                                                                  \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " conv4_block3_0_bn (BatchNormal  (None, 8, 8, 320)   1280        ['conv4_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_0_relu (Activatio  (None, 8, 8, 320)   0           ['conv4_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block3_1_conv (Conv2D)   (None, 8, 8, 128)    40960       ['conv4_block3_0_relu[0][0]']    \n                                                                                                  \n conv4_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block3_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block3_1_relu[0][0]']    \n                                                                                                  \n conv4_block3_concat (Concatena  (None, 8, 8, 352)   0           ['conv4_block2_concat[0][0]',    \n te)                                                              'conv4_block3_2_conv[0][0]']    \n                                                                                                  \n conv4_block4_0_bn (BatchNormal  (None, 8, 8, 352)   1408        ['conv4_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_0_relu (Activatio  (None, 8, 8, 352)   0           ['conv4_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block4_1_conv (Conv2D)   (None, 8, 8, 128)    45056       ['conv4_block4_0_relu[0][0]']    \n                                                                                                  \n conv4_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block4_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block4_1_relu[0][0]']    \n                                                                                                  \n conv4_block4_concat (Concatena  (None, 8, 8, 384)   0           ['conv4_block3_concat[0][0]',    \n te)                                                              'conv4_block4_2_conv[0][0]']    \n                                                                                                  \n conv4_block5_0_bn (BatchNormal  (None, 8, 8, 384)   1536        ['conv4_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_0_relu (Activatio  (None, 8, 8, 384)   0           ['conv4_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block5_1_conv (Conv2D)   (None, 8, 8, 128)    49152       ['conv4_block5_0_relu[0][0]']    \n                                                                                                  \n conv4_block5_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block5_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block5_1_relu[0][0]']    \n                                                                                                  \n conv4_block5_concat (Concatena  (None, 8, 8, 416)   0           ['conv4_block4_concat[0][0]',    \n te)                                                              'conv4_block5_2_conv[0][0]']    \n                                                                                                  \n conv4_block6_0_bn (BatchNormal  (None, 8, 8, 416)   1664        ['conv4_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_0_relu (Activatio  (None, 8, 8, 416)   0           ['conv4_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block6_1_conv (Conv2D)   (None, 8, 8, 128)    53248       ['conv4_block6_0_relu[0][0]']    \n                                                                                                  \n conv4_block6_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block6_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block6_1_relu[0][0]']    \n                                                                                                  \n conv4_block6_concat (Concatena  (None, 8, 8, 448)   0           ['conv4_block5_concat[0][0]',    \n te)                                                              'conv4_block6_2_conv[0][0]']    \n                                                                                                  \n conv4_block7_0_bn (BatchNormal  (None, 8, 8, 448)   1792        ['conv4_block6_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block7_0_relu (Activatio  (None, 8, 8, 448)   0           ['conv4_block7_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block7_1_conv (Conv2D)   (None, 8, 8, 128)    57344       ['conv4_block7_0_relu[0][0]']    \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "                                                                                                  \n conv4_block7_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block7_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block7_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block7_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block7_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block7_1_relu[0][0]']    \n                                                                                                  \n conv4_block7_concat (Concatena  (None, 8, 8, 480)   0           ['conv4_block6_concat[0][0]',    \n te)                                                              'conv4_block7_2_conv[0][0]']    \n                                                                                                  \n conv4_block8_0_bn (BatchNormal  (None, 8, 8, 480)   1920        ['conv4_block7_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block8_0_relu (Activatio  (None, 8, 8, 480)   0           ['conv4_block8_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block8_1_conv (Conv2D)   (None, 8, 8, 128)    61440       ['conv4_block8_0_relu[0][0]']    \n                                                                                                  \n conv4_block8_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block8_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block8_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block8_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block8_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block8_1_relu[0][0]']    \n                                                                                                  \n conv4_block8_concat (Concatena  (None, 8, 8, 512)   0           ['conv4_block7_concat[0][0]',    \n te)                                                              'conv4_block8_2_conv[0][0]']    \n                                                                                                  \n conv4_block9_0_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv4_block8_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block9_0_relu (Activatio  (None, 8, 8, 512)   0           ['conv4_block9_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block9_1_conv (Conv2D)   (None, 8, 8, 128)    65536       ['conv4_block9_0_relu[0][0]']    \n                                                                                                  \n conv4_block9_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block9_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block9_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block9_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block9_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block9_1_relu[0][0]']    \n                                                                                                  \n conv4_block9_concat (Concatena  (None, 8, 8, 544)   0           ['conv4_block8_concat[0][0]',    \n te)                                                              'conv4_block9_2_conv[0][0]']    \n                                                                                                  \n conv4_block10_0_bn (BatchNorma  (None, 8, 8, 544)   2176        ['conv4_block9_concat[0][0]']    \n lization)                                                                                        \n                                                                                                  \n conv4_block10_0_relu (Activati  (None, 8, 8, 544)   0           ['conv4_block10_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block10_1_conv (Conv2D)  (None, 8, 8, 128)    69632       ['conv4_block10_0_relu[0][0]']   \n                                                                                                  \n conv4_block10_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block10_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block10_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block10_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block10_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block10_1_relu[0][0]']   \n                                                                                                  \n conv4_block10_concat (Concaten  (None, 8, 8, 576)   0           ['conv4_block9_concat[0][0]',    \n ate)                                                             'conv4_block10_2_conv[0][0]']   \n                                                                                                  \n conv4_block11_0_bn (BatchNorma  (None, 8, 8, 576)   2304        ['conv4_block10_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block11_0_relu (Activati  (None, 8, 8, 576)   0           ['conv4_block11_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block11_1_conv (Conv2D)  (None, 8, 8, 128)    73728       ['conv4_block11_0_relu[0][0]']   \n                                                                                                  \n conv4_block11_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block11_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block11_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block11_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " conv4_block11_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block11_1_relu[0][0]']   \n                                                                                                  \n conv4_block11_concat (Concaten  (None, 8, 8, 608)   0           ['conv4_block10_concat[0][0]',   \n ate)                                                             'conv4_block11_2_conv[0][0]']   \n                                                                                                  \n conv4_block12_0_bn (BatchNorma  (None, 8, 8, 608)   2432        ['conv4_block11_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block12_0_relu (Activati  (None, 8, 8, 608)   0           ['conv4_block12_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block12_1_conv (Conv2D)  (None, 8, 8, 128)    77824       ['conv4_block12_0_relu[0][0]']   \n                                                                                                  \n conv4_block12_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block12_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block12_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block12_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block12_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block12_1_relu[0][0]']   \n                                                                                                  \n conv4_block12_concat (Concaten  (None, 8, 8, 640)   0           ['conv4_block11_concat[0][0]',   \n ate)                                                             'conv4_block12_2_conv[0][0]']   \n                                                                                                  \n conv4_block13_0_bn (BatchNorma  (None, 8, 8, 640)   2560        ['conv4_block12_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block13_0_relu (Activati  (None, 8, 8, 640)   0           ['conv4_block13_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block13_1_conv (Conv2D)  (None, 8, 8, 128)    81920       ['conv4_block13_0_relu[0][0]']   \n                                                                                                  \n conv4_block13_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block13_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block13_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block13_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block13_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block13_1_relu[0][0]']   \n                                                                                                  \n conv4_block13_concat (Concaten  (None, 8, 8, 672)   0           ['conv4_block12_concat[0][0]',   \n ate)                                                             'conv4_block13_2_conv[0][0]']   \n                                                                                                  \n conv4_block14_0_bn (BatchNorma  (None, 8, 8, 672)   2688        ['conv4_block13_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block14_0_relu (Activati  (None, 8, 8, 672)   0           ['conv4_block14_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block14_1_conv (Conv2D)  (None, 8, 8, 128)    86016       ['conv4_block14_0_relu[0][0]']   \n                                                                                                  \n conv4_block14_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block14_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block14_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block14_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block14_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block14_1_relu[0][0]']   \n                                                                                                  \n conv4_block14_concat (Concaten  (None, 8, 8, 704)   0           ['conv4_block13_concat[0][0]',   \n ate)                                                             'conv4_block14_2_conv[0][0]']   \n                                                                                                  \n conv4_block15_0_bn (BatchNorma  (None, 8, 8, 704)   2816        ['conv4_block14_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block15_0_relu (Activati  (None, 8, 8, 704)   0           ['conv4_block15_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block15_1_conv (Conv2D)  (None, 8, 8, 128)    90112       ['conv4_block15_0_relu[0][0]']   \n                                                                                                  \n conv4_block15_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block15_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block15_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block15_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block15_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block15_1_relu[0][0]']   \n                                                                                                  \n conv4_block15_concat (Concaten  (None, 8, 8, 736)   0           ['conv4_block14_concat[0][0]',   \n ate)                                                             'conv4_block15_2_conv[0][0]']   \n                                                                                                  \n conv4_block16_0_bn (BatchNorma  (None, 8, 8, 736)   2944        ['conv4_block15_concat[0][0]']   \n lization)                                                                                        \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "                                                                                                  \n conv4_block16_0_relu (Activati  (None, 8, 8, 736)   0           ['conv4_block16_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block16_1_conv (Conv2D)  (None, 8, 8, 128)    94208       ['conv4_block16_0_relu[0][0]']   \n                                                                                                  \n conv4_block16_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block16_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block16_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block16_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block16_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block16_1_relu[0][0]']   \n                                                                                                  \n conv4_block16_concat (Concaten  (None, 8, 8, 768)   0           ['conv4_block15_concat[0][0]',   \n ate)                                                             'conv4_block16_2_conv[0][0]']   \n                                                                                                  \n conv4_block17_0_bn (BatchNorma  (None, 8, 8, 768)   3072        ['conv4_block16_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block17_0_relu (Activati  (None, 8, 8, 768)   0           ['conv4_block17_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block17_1_conv (Conv2D)  (None, 8, 8, 128)    98304       ['conv4_block17_0_relu[0][0]']   \n                                                                                                  \n conv4_block17_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block17_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block17_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block17_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block17_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block17_1_relu[0][0]']   \n                                                                                                  \n conv4_block17_concat (Concaten  (None, 8, 8, 800)   0           ['conv4_block16_concat[0][0]',   \n ate)                                                             'conv4_block17_2_conv[0][0]']   \n                                                                                                  \n conv4_block18_0_bn (BatchNorma  (None, 8, 8, 800)   3200        ['conv4_block17_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block18_0_relu (Activati  (None, 8, 8, 800)   0           ['conv4_block18_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block18_1_conv (Conv2D)  (None, 8, 8, 128)    102400      ['conv4_block18_0_relu[0][0]']   \n                                                                                                  \n conv4_block18_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block18_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block18_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block18_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block18_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block18_1_relu[0][0]']   \n                                                                                                  \n conv4_block18_concat (Concaten  (None, 8, 8, 832)   0           ['conv4_block17_concat[0][0]',   \n ate)                                                             'conv4_block18_2_conv[0][0]']   \n                                                                                                  \n conv4_block19_0_bn (BatchNorma  (None, 8, 8, 832)   3328        ['conv4_block18_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block19_0_relu (Activati  (None, 8, 8, 832)   0           ['conv4_block19_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block19_1_conv (Conv2D)  (None, 8, 8, 128)    106496      ['conv4_block19_0_relu[0][0]']   \n                                                                                                  \n conv4_block19_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block19_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block19_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block19_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block19_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block19_1_relu[0][0]']   \n                                                                                                  \n conv4_block19_concat (Concaten  (None, 8, 8, 864)   0           ['conv4_block18_concat[0][0]',   \n ate)                                                             'conv4_block19_2_conv[0][0]']   \n                                                                                                  \n conv4_block20_0_bn (BatchNorma  (None, 8, 8, 864)   3456        ['conv4_block19_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block20_0_relu (Activati  (None, 8, 8, 864)   0           ['conv4_block20_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block20_1_conv (Conv2D)  (None, 8, 8, 128)    110592      ['conv4_block20_0_relu[0][0]']   \n                                                                                                  \n conv4_block20_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block20_1_conv[0][0]']   \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " lization)                                                                                        \n                                                                                                  \n conv4_block20_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block20_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block20_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block20_1_relu[0][0]']   \n                                                                                                  \n conv4_block20_concat (Concaten  (None, 8, 8, 896)   0           ['conv4_block19_concat[0][0]',   \n ate)                                                             'conv4_block20_2_conv[0][0]']   \n                                                                                                  \n conv4_block21_0_bn (BatchNorma  (None, 8, 8, 896)   3584        ['conv4_block20_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block21_0_relu (Activati  (None, 8, 8, 896)   0           ['conv4_block21_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block21_1_conv (Conv2D)  (None, 8, 8, 128)    114688      ['conv4_block21_0_relu[0][0]']   \n                                                                                                  \n conv4_block21_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block21_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block21_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block21_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block21_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block21_1_relu[0][0]']   \n                                                                                                  \n conv4_block21_concat (Concaten  (None, 8, 8, 928)   0           ['conv4_block20_concat[0][0]',   \n ate)                                                             'conv4_block21_2_conv[0][0]']   \n                                                                                                  \n conv4_block22_0_bn (BatchNorma  (None, 8, 8, 928)   3712        ['conv4_block21_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block22_0_relu (Activati  (None, 8, 8, 928)   0           ['conv4_block22_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block22_1_conv (Conv2D)  (None, 8, 8, 128)    118784      ['conv4_block22_0_relu[0][0]']   \n                                                                                                  \n conv4_block22_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block22_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block22_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block22_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block22_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block22_1_relu[0][0]']   \n                                                                                                  \n conv4_block22_concat (Concaten  (None, 8, 8, 960)   0           ['conv4_block21_concat[0][0]',   \n ate)                                                             'conv4_block22_2_conv[0][0]']   \n                                                                                                  \n conv4_block23_0_bn (BatchNorma  (None, 8, 8, 960)   3840        ['conv4_block22_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block23_0_relu (Activati  (None, 8, 8, 960)   0           ['conv4_block23_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block23_1_conv (Conv2D)  (None, 8, 8, 128)    122880      ['conv4_block23_0_relu[0][0]']   \n                                                                                                  \n conv4_block23_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block23_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block23_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block23_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block23_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block23_1_relu[0][0]']   \n                                                                                                  \n conv4_block23_concat (Concaten  (None, 8, 8, 992)   0           ['conv4_block22_concat[0][0]',   \n ate)                                                             'conv4_block23_2_conv[0][0]']   \n                                                                                                  \n conv4_block24_0_bn (BatchNorma  (None, 8, 8, 992)   3968        ['conv4_block23_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block24_0_relu (Activati  (None, 8, 8, 992)   0           ['conv4_block24_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block24_1_conv (Conv2D)  (None, 8, 8, 128)    126976      ['conv4_block24_0_relu[0][0]']   \n                                                                                                  \n conv4_block24_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block24_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block24_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block24_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block24_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block24_1_relu[0][0]']   \n                                                                                                  \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " conv4_block24_concat (Concaten  (None, 8, 8, 1024)  0           ['conv4_block23_concat[0][0]',   \n ate)                                                             'conv4_block24_2_conv[0][0]']   \n                                                                                                  \n pool4_bn (BatchNormalization)  (None, 8, 8, 1024)   4096        ['conv4_block24_concat[0][0]']   \n                                                                                                  \n pool4_relu (Activation)        (None, 8, 8, 1024)   0           ['pool4_bn[0][0]']               \n                                                                                                  \n pool4_conv (Conv2D)            (None, 8, 8, 512)    524288      ['pool4_relu[0][0]']             \n                                                                                                  \n pool4_pool (AveragePooling2D)  (None, 4, 4, 512)    0           ['pool4_conv[0][0]']             \n                                                                                                  \n conv5_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['pool4_pool[0][0]']             \n ization)                                                                                         \n                                                                                                  \n conv5_block1_0_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block1_1_conv (Conv2D)   (None, 4, 4, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n                                                                                                  \n conv5_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block1_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n                                                                                                  \n conv5_block1_concat (Concatena  (None, 4, 4, 544)   0           ['pool4_pool[0][0]',             \n te)                                                              'conv5_block1_2_conv[0][0]']    \n                                                                                                  \n conv5_block2_0_bn (BatchNormal  (None, 4, 4, 544)   2176        ['conv5_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_0_relu (Activatio  (None, 4, 4, 544)   0           ['conv5_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block2_1_conv (Conv2D)   (None, 4, 4, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n                                                                                                  \n conv5_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block2_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n                                                                                                  \n conv5_block2_concat (Concatena  (None, 4, 4, 576)   0           ['conv5_block1_concat[0][0]',    \n te)                                                              'conv5_block2_2_conv[0][0]']    \n                                                                                                  \n conv5_block3_0_bn (BatchNormal  (None, 4, 4, 576)   2304        ['conv5_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_0_relu (Activatio  (None, 4, 4, 576)   0           ['conv5_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block3_1_conv (Conv2D)   (None, 4, 4, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n                                                                                                  \n conv5_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block3_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n                                                                                                  \n conv5_block3_concat (Concatena  (None, 4, 4, 608)   0           ['conv5_block2_concat[0][0]',    \n te)                                                              'conv5_block3_2_conv[0][0]']    \n                                                                                                  \n conv5_block4_0_bn (BatchNormal  (None, 4, 4, 608)   2432        ['conv5_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block4_0_relu (Activatio  (None, 4, 4, 608)   0           ['conv5_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block4_1_conv (Conv2D)   (None, 4, 4, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n                                                                                                  \n conv5_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block4_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "                                                                                                  \n conv5_block4_concat (Concatena  (None, 4, 4, 640)   0           ['conv5_block3_concat[0][0]',    \n te)                                                              'conv5_block4_2_conv[0][0]']    \n                                                                                                  \n conv5_block5_0_bn (BatchNormal  (None, 4, 4, 640)   2560        ['conv5_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block5_0_relu (Activatio  (None, 4, 4, 640)   0           ['conv5_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block5_1_conv (Conv2D)   (None, 4, 4, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n                                                                                                  \n conv5_block5_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block5_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block5_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n                                                                                                  \n conv5_block5_concat (Concatena  (None, 4, 4, 672)   0           ['conv5_block4_concat[0][0]',    \n te)                                                              'conv5_block5_2_conv[0][0]']    \n                                                                                                  \n conv5_block6_0_bn (BatchNormal  (None, 4, 4, 672)   2688        ['conv5_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block6_0_relu (Activatio  (None, 4, 4, 672)   0           ['conv5_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block6_1_conv (Conv2D)   (None, 4, 4, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n                                                                                                  \n conv5_block6_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block6_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block6_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n                                                                                                  \n conv5_block6_concat (Concatena  (None, 4, 4, 704)   0           ['conv5_block5_concat[0][0]',    \n te)                                                              'conv5_block6_2_conv[0][0]']    \n                                                                                                  \n conv5_block7_0_bn (BatchNormal  (None, 4, 4, 704)   2816        ['conv5_block6_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block7_0_relu (Activatio  (None, 4, 4, 704)   0           ['conv5_block7_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block7_1_conv (Conv2D)   (None, 4, 4, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n                                                                                                  \n conv5_block7_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block7_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block7_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block7_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block7_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n                                                                                                  \n conv5_block7_concat (Concatena  (None, 4, 4, 736)   0           ['conv5_block6_concat[0][0]',    \n te)                                                              'conv5_block7_2_conv[0][0]']    \n                                                                                                  \n conv5_block8_0_bn (BatchNormal  (None, 4, 4, 736)   2944        ['conv5_block7_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block8_0_relu (Activatio  (None, 4, 4, 736)   0           ['conv5_block8_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block8_1_conv (Conv2D)   (None, 4, 4, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n                                                                                                  \n conv5_block8_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block8_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block8_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block8_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block8_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n                                                                                                  \n conv5_block8_concat (Concatena  (None, 4, 4, 768)   0           ['conv5_block7_concat[0][0]',    \n te)                                                              'conv5_block8_2_conv[0][0]']    \n                                                                                                  \n conv5_block9_0_bn (BatchNormal  (None, 4, 4, 768)   3072        ['conv5_block8_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " conv5_block9_0_relu (Activatio  (None, 4, 4, 768)   0           ['conv5_block9_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block9_1_conv (Conv2D)   (None, 4, 4, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n                                                                                                  \n conv5_block9_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block9_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block9_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block9_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block9_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n                                                                                                  \n conv5_block9_concat (Concatena  (None, 4, 4, 800)   0           ['conv5_block8_concat[0][0]',    \n te)                                                              'conv5_block9_2_conv[0][0]']    \n                                                                                                  \n conv5_block10_0_bn (BatchNorma  (None, 4, 4, 800)   3200        ['conv5_block9_concat[0][0]']    \n lization)                                                                                        \n                                                                                                  \n conv5_block10_0_relu (Activati  (None, 4, 4, 800)   0           ['conv5_block10_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block10_1_conv (Conv2D)  (None, 4, 4, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n                                                                                                  \n conv5_block10_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block10_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block10_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block10_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block10_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n                                                                                                  \n conv5_block10_concat (Concaten  (None, 4, 4, 832)   0           ['conv5_block9_concat[0][0]',    \n ate)                                                             'conv5_block10_2_conv[0][0]']   \n                                                                                                  \n conv5_block11_0_bn (BatchNorma  (None, 4, 4, 832)   3328        ['conv5_block10_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block11_0_relu (Activati  (None, 4, 4, 832)   0           ['conv5_block11_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block11_1_conv (Conv2D)  (None, 4, 4, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n                                                                                                  \n conv5_block11_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block11_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block11_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block11_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block11_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n                                                                                                  \n conv5_block11_concat (Concaten  (None, 4, 4, 864)   0           ['conv5_block10_concat[0][0]',   \n ate)                                                             'conv5_block11_2_conv[0][0]']   \n                                                                                                  \n conv5_block12_0_bn (BatchNorma  (None, 4, 4, 864)   3456        ['conv5_block11_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block12_0_relu (Activati  (None, 4, 4, 864)   0           ['conv5_block12_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block12_1_conv (Conv2D)  (None, 4, 4, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n                                                                                                  \n conv5_block12_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block12_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block12_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block12_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block12_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n                                                                                                  \n conv5_block12_concat (Concaten  (None, 4, 4, 896)   0           ['conv5_block11_concat[0][0]',   \n ate)                                                             'conv5_block12_2_conv[0][0]']   \n                                                                                                  \n conv5_block13_0_bn (BatchNorma  (None, 4, 4, 896)   3584        ['conv5_block12_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block13_0_relu (Activati  (None, 4, 4, 896)   0           ['conv5_block13_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block13_1_conv (Conv2D)  (None, 4, 4, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n                                                                                                  \n conv5_block13_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block13_1_conv[0][0]']   \n lization)                                                                                        \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "                                                                                                  \n conv5_block13_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block13_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block13_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n                                                                                                  \n conv5_block13_concat (Concaten  (None, 4, 4, 928)   0           ['conv5_block12_concat[0][0]',   \n ate)                                                             'conv5_block13_2_conv[0][0]']   \n                                                                                                  \n conv5_block14_0_bn (BatchNorma  (None, 4, 4, 928)   3712        ['conv5_block13_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block14_0_relu (Activati  (None, 4, 4, 928)   0           ['conv5_block14_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block14_1_conv (Conv2D)  (None, 4, 4, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n                                                                                                  \n conv5_block14_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block14_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block14_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block14_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block14_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n                                                                                                  \n conv5_block14_concat (Concaten  (None, 4, 4, 960)   0           ['conv5_block13_concat[0][0]',   \n ate)                                                             'conv5_block14_2_conv[0][0]']   \n                                                                                                  \n conv5_block15_0_bn (BatchNorma  (None, 4, 4, 960)   3840        ['conv5_block14_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block15_0_relu (Activati  (None, 4, 4, 960)   0           ['conv5_block15_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block15_1_conv (Conv2D)  (None, 4, 4, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n                                                                                                  \n conv5_block15_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block15_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block15_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block15_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block15_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n                                                                                                  \n conv5_block15_concat (Concaten  (None, 4, 4, 992)   0           ['conv5_block14_concat[0][0]',   \n ate)                                                             'conv5_block15_2_conv[0][0]']   \n                                                                                                  \n conv5_block16_0_bn (BatchNorma  (None, 4, 4, 992)   3968        ['conv5_block15_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block16_0_relu (Activati  (None, 4, 4, 992)   0           ['conv5_block16_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block16_1_conv (Conv2D)  (None, 4, 4, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n                                                                                                  \n conv5_block16_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block16_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block16_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block16_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block16_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n                                                                                                  \n conv5_block16_concat (Concaten  (None, 4, 4, 1024)  0           ['conv5_block15_concat[0][0]',   \n ate)                                                             'conv5_block16_2_conv[0][0]']   \n                                                                                                  \n bn (BatchNormalization)        (None, 4, 4, 1024)   4096        ['conv5_block16_concat[0][0]']   \n                                                                                                  \n relu (Activation)              (None, 4, 4, 1024)   0           ['bn[0][0]']                     \n                                                                                                  \n average_pooling2d_2 (AveragePo  (None, 2, 2, 1024)  0           ['relu[0][0]']                   \n oling2D)                                                                                         \n                                                                                                  \n flatten_2 (Flatten)            (None, 4096)         0           ['average_pooling2d_2[0][0]']    \n                                                                                                  \n dropout_2 (Dropout)            (None, 4096)         0           ['flatten_2[0][0]']              \n                                                                                                  \n dense_2 (Dense)                (None, 120)          491640      ['dropout_2[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 7,529,144\nTrainable params: 491,640\nNon-trainable params: 7,037,504\n__________________________________________________________________________________________________\n"
                }
            ],
            "execution_count": 24
        },
        {
            "cell_type": "code",
            "source": [
                "m3_model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
            ],
            "metadata": {
                "id": "9cGZi7nJ5LG1",
                "azdata_cell_guid": "914125d9-73f6-4890-93b1-ce1f904e58d4",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 25
        },
        {
            "cell_type": "code",
            "source": [
                "m3_model.fit(X_train, y_train, epochs=20, batch_size=32, callbacks=[earlystop], validation_data = (X_test, y_test))"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 631279,
                    "status": "ok",
                    "timestamp": 1680058145562,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "2Zhf3cnS7BXV",
                "jupyter": {
                    "outputs_hidden": true
                },
                "outputId": "e8b26db7-0358-4eed-f254-a6099fc2d4aa",
                "tags": [],
                "azdata_cell_guid": "c1ceb489-242d-4712-a457-7d3c2fd5369a",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Epoch 1/20\n256/256 [==============================] - 231s 880ms/step - loss: 20.5877 - accuracy: 0.0291 - val_loss: 15.4376 - val_accuracy: 0.0406\nEpoch 2/20\n256/256 [==============================] - 220s 861ms/step - loss: 14.9473 - accuracy: 0.0846 - val_loss: 18.0870 - val_accuracy: 0.0626\nEpoch 3/20\n256/256 [==============================] - 221s 865ms/step - loss: 12.1624 - accuracy: 0.1519 - val_loss: 17.4223 - val_accuracy: 0.0533\nEpoch 4/20\n256/256 [==============================] - 218s 853ms/step - loss: 10.5353 - accuracy: 0.2167 - val_loss: 17.6494 - val_accuracy: 0.0606\nEpoch 5/20\n256/256 [==============================] - 220s 859ms/step - loss: 9.1472 - accuracy: 0.2656 - val_loss: 18.0834 - val_accuracy: 0.0670\nEpoch 6/20\n256/256 [==============================] - 220s 858ms/step - loss: 8.0962 - accuracy: 0.3166 - val_loss: 18.8536 - val_accuracy: 0.0631\nEpoch 7/20\n256/256 [==============================] - 223s 873ms/step - loss: 7.5359 - accuracy: 0.3450 - val_loss: 18.8407 - val_accuracy: 0.0704\nEpoch 8/20\n256/256 [==============================] - 222s 867ms/step - loss: 6.8537 - accuracy: 0.3853 - val_loss: 18.8465 - val_accuracy: 0.0797\nEpoch 9/20\n256/256 [==============================] - 222s 869ms/step - loss: 6.3649 - accuracy: 0.4181 - val_loss: 20.3499 - val_accuracy: 0.0817\nEpoch 10/20\n256/256 [==============================] - 219s 855ms/step - loss: 6.2103 - accuracy: 0.4361 - val_loss: 20.8711 - val_accuracy: 0.0724\nEpoch 11/20\n256/256 [==============================] - 220s 860ms/step - loss: 5.7455 - accuracy: 0.4613 - val_loss: 22.3610 - val_accuracy: 0.0665\nEpoch 12/20\n256/256 [==============================] - 218s 852ms/step - loss: 5.3852 - accuracy: 0.4776 - val_loss: 21.3525 - val_accuracy: 0.0792\nEpoch 13/20\n256/256 [==============================] - 220s 861ms/step - loss: 5.3695 - accuracy: 0.4913 - val_loss: 23.4357 - val_accuracy: 0.0841\nEpoch 14/20\n256/256 [==============================] - 219s 857ms/step - loss: 5.0231 - accuracy: 0.5217 - val_loss: 23.7960 - val_accuracy: 0.0768\nEpoch 15/20\n256/256 [==============================] - 222s 868ms/step - loss: 4.9724 - accuracy: 0.5298 - val_loss: 23.2294 - val_accuracy: 0.0812\nEpoch 16/20\n256/256 [==============================] - 223s 871ms/step - loss: 4.9458 - accuracy: 0.5271 - val_loss: 24.2473 - val_accuracy: 0.0738\nEpoch 17/20\n256/256 [==============================] - 222s 867ms/step - loss: 4.6534 - accuracy: 0.5630 - val_loss: 25.8793 - val_accuracy: 0.0738\nEpoch 18/20\n256/256 [==============================] - 220s 861ms/step - loss: 4.7584 - accuracy: 0.5668 - val_loss: 26.3474 - val_accuracy: 0.0768\nEpoch 19/20\n256/256 [==============================] - 223s 870ms/step - loss: 4.5328 - accuracy: 0.5786 - val_loss: 25.9370 - val_accuracy: 0.0826\nEpoch 20/20\n256/256 [==============================] - 220s 859ms/step - loss: 4.5912 - accuracy: 0.5859 - val_loss: 26.4161 - val_accuracy: 0.0812\n"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 26,
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x25c0a8e69e0>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 26
        },
        {
            "cell_type": "markdown",
            "source": [
                "EfficientNet model creation with an extra pooling layer, flatten layer, and dense layer."
            ],
            "metadata": {
                "id": "Wksth2cpDl8P",
                "azdata_cell_guid": "12ef2af9-fd0e-4ef8-970f-cbeb253f3688"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "m4=tf.keras.applications.efficientnet.EfficientNetB0(weights='imagenet',include_top=False, input_shape=(128, 128, 3))\n",
                "m4.trainable = False\n",
                "\n",
                "x = m4.output\n",
                "x = AveragePooling2D()(x)\n",
                "x = Flatten()(x)\n",
                "x = Dropout(.2)(x)\n",
                "x = Dense(120, activation='softmax')(x)\n",
                "m4_model = Model(inputs=m4.input, outputs=x)\n",
                "m4_model.summary()"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 9506,
                    "status": "ok",
                    "timestamp": 1680050818478,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "KSmpEaTBvQS7",
                "jupyter": {
                    "outputs_hidden": true
                },
                "outputId": "4cdd3313-44c2-476d-b24c-e8cd426ef974",
                "tags": [],
                "azdata_cell_guid": "ac78ab6f-5cfa-42dd-9310-9db2cad977ce",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Model: \"model_3\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_4 (InputLayer)           [(None, 128, 128, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n rescaling (Rescaling)          (None, 128, 128, 3)  0           ['input_4[0][0]']                \n                                                                                                  \n normalization (Normalization)  (None, 128, 128, 3)  7           ['rescaling[0][0]']              \n                                                                                                  \n rescaling_1 (Rescaling)        (None, 128, 128, 3)  0           ['normalization[0][0]']          \n                                                                                                  \n stem_conv_pad (ZeroPadding2D)  (None, 129, 129, 3)  0           ['rescaling_1[0][0]']            \n                                                                                                  \n stem_conv (Conv2D)             (None, 64, 64, 32)   864         ['stem_conv_pad[0][0]']          \n                                                                                                  \n stem_bn (BatchNormalization)   (None, 64, 64, 32)   128         ['stem_conv[0][0]']              \n                                                                                                  \n stem_activation (Activation)   (None, 64, 64, 32)   0           ['stem_bn[0][0]']                \n                                                                                                  \n block1a_dwconv (DepthwiseConv2  (None, 64, 64, 32)  288         ['stem_activation[0][0]']        \n D)                                                                                               \n                                                                                                  \n block1a_bn (BatchNormalization  (None, 64, 64, 32)  128         ['block1a_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block1a_activation (Activation  (None, 64, 64, 32)  0           ['block1a_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n                                                                                                  \n block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n                                                                                                  \n block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n                                                                                                  \n block1a_se_excite (Multiply)   (None, 64, 64, 32)   0           ['block1a_activation[0][0]',     \n                                                                  'block1a_se_expand[0][0]']      \n                                                                                                  \n block1a_project_conv (Conv2D)  (None, 64, 64, 16)   512         ['block1a_se_excite[0][0]']      \n                                                                                                  \n block1a_project_bn (BatchNorma  (None, 64, 64, 16)  64          ['block1a_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block2a_expand_conv (Conv2D)   (None, 64, 64, 96)   1536        ['block1a_project_bn[0][0]']     \n                                                                                                  \n block2a_expand_bn (BatchNormal  (None, 64, 64, 96)  384         ['block2a_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block2a_expand_activation (Act  (None, 64, 64, 96)  0           ['block2a_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block2a_dwconv_pad (ZeroPaddin  (None, 65, 65, 96)  0           ['block2a_expand_activation[0][0]\n g2D)                                                            ']                               \n                                                                                                  \n block2a_dwconv (DepthwiseConv2  (None, 32, 32, 96)  864         ['block2a_dwconv_pad[0][0]']     \n D)                                                                                               \n                                                                                                  \n block2a_bn (BatchNormalization  (None, 32, 32, 96)  384         ['block2a_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block2a_activation (Activation  (None, 32, 32, 96)  0           ['block2a_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n                                                                                                  \n block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n                                                                                                  \n block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n                                                                                                  \n block2a_se_excite (Multiply)   (None, 32, 32, 96)   0           ['block2a_activation[0][0]',     \n                                                                  'block2a_se_expand[0][0]']      \n                                                                                                  \n block2a_project_conv (Conv2D)  (None, 32, 32, 24)   2304        ['block2a_se_excite[0][0]']      \n                                                                                                  \n block2a_project_bn (BatchNorma  (None, 32, 32, 24)  96          ['block2a_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " block2b_expand_conv (Conv2D)   (None, 32, 32, 144)  3456        ['block2a_project_bn[0][0]']     \n                                                                                                  \n block2b_expand_bn (BatchNormal  (None, 32, 32, 144)  576        ['block2b_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block2b_expand_activation (Act  (None, 32, 32, 144)  0          ['block2b_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block2b_dwconv (DepthwiseConv2  (None, 32, 32, 144)  1296       ['block2b_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block2b_bn (BatchNormalization  (None, 32, 32, 144)  576        ['block2b_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block2b_activation (Activation  (None, 32, 32, 144)  0          ['block2b_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n                                                                                                  \n block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n                                                                                                  \n block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n                                                                                                  \n block2b_se_excite (Multiply)   (None, 32, 32, 144)  0           ['block2b_activation[0][0]',     \n                                                                  'block2b_se_expand[0][0]']      \n                                                                                                  \n block2b_project_conv (Conv2D)  (None, 32, 32, 24)   3456        ['block2b_se_excite[0][0]']      \n                                                                                                  \n block2b_project_bn (BatchNorma  (None, 32, 32, 24)  96          ['block2b_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block2b_drop (Dropout)         (None, 32, 32, 24)   0           ['block2b_project_bn[0][0]']     \n                                                                                                  \n block2b_add (Add)              (None, 32, 32, 24)   0           ['block2b_drop[0][0]',           \n                                                                  'block2a_project_bn[0][0]']     \n                                                                                                  \n block3a_expand_conv (Conv2D)   (None, 32, 32, 144)  3456        ['block2b_add[0][0]']            \n                                                                                                  \n block3a_expand_bn (BatchNormal  (None, 32, 32, 144)  576        ['block3a_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block3a_expand_activation (Act  (None, 32, 32, 144)  0          ['block3a_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block3a_dwconv_pad (ZeroPaddin  (None, 35, 35, 144)  0          ['block3a_expand_activation[0][0]\n g2D)                                                            ']                               \n                                                                                                  \n block3a_dwconv (DepthwiseConv2  (None, 16, 16, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n D)                                                                                               \n                                                                                                  \n block3a_bn (BatchNormalization  (None, 16, 16, 144)  576        ['block3a_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block3a_activation (Activation  (None, 16, 16, 144)  0          ['block3a_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n                                                                                                  \n block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n                                                                                                  \n block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n                                                                                                  \n block3a_se_excite (Multiply)   (None, 16, 16, 144)  0           ['block3a_activation[0][0]',     \n                                                                  'block3a_se_expand[0][0]']      \n                                                                                                  \n block3a_project_conv (Conv2D)  (None, 16, 16, 40)   5760        ['block3a_se_excite[0][0]']      \n                                                                                                  \n block3a_project_bn (BatchNorma  (None, 16, 16, 40)  160         ['block3a_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block3b_expand_conv (Conv2D)   (None, 16, 16, 240)  9600        ['block3a_project_bn[0][0]']     \n                                                                                                  \n block3b_expand_bn (BatchNormal  (None, 16, 16, 240)  960        ['block3b_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block3b_expand_activation (Act  (None, 16, 16, 240)  0          ['block3b_expand_bn[0][0]']      \n ivation)                                                                                         \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "                                                                                                  \n block3b_dwconv (DepthwiseConv2  (None, 16, 16, 240)  6000       ['block3b_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block3b_bn (BatchNormalization  (None, 16, 16, 240)  960        ['block3b_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block3b_activation (Activation  (None, 16, 16, 240)  0          ['block3b_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n                                                                                                  \n block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n                                                                                                  \n block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n                                                                                                  \n block3b_se_excite (Multiply)   (None, 16, 16, 240)  0           ['block3b_activation[0][0]',     \n                                                                  'block3b_se_expand[0][0]']      \n                                                                                                  \n block3b_project_conv (Conv2D)  (None, 16, 16, 40)   9600        ['block3b_se_excite[0][0]']      \n                                                                                                  \n block3b_project_bn (BatchNorma  (None, 16, 16, 40)  160         ['block3b_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block3b_drop (Dropout)         (None, 16, 16, 40)   0           ['block3b_project_bn[0][0]']     \n                                                                                                  \n block3b_add (Add)              (None, 16, 16, 40)   0           ['block3b_drop[0][0]',           \n                                                                  'block3a_project_bn[0][0]']     \n                                                                                                  \n block4a_expand_conv (Conv2D)   (None, 16, 16, 240)  9600        ['block3b_add[0][0]']            \n                                                                                                  \n block4a_expand_bn (BatchNormal  (None, 16, 16, 240)  960        ['block4a_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block4a_expand_activation (Act  (None, 16, 16, 240)  0          ['block4a_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block4a_dwconv_pad (ZeroPaddin  (None, 17, 17, 240)  0          ['block4a_expand_activation[0][0]\n g2D)                                                            ']                               \n                                                                                                  \n block4a_dwconv (DepthwiseConv2  (None, 8, 8, 240)   2160        ['block4a_dwconv_pad[0][0]']     \n D)                                                                                               \n                                                                                                  \n block4a_bn (BatchNormalization  (None, 8, 8, 240)   960         ['block4a_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block4a_activation (Activation  (None, 8, 8, 240)   0           ['block4a_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n                                                                                                  \n block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n                                                                                                  \n block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n                                                                                                  \n block4a_se_excite (Multiply)   (None, 8, 8, 240)    0           ['block4a_activation[0][0]',     \n                                                                  'block4a_se_expand[0][0]']      \n                                                                                                  \n block4a_project_conv (Conv2D)  (None, 8, 8, 80)     19200       ['block4a_se_excite[0][0]']      \n                                                                                                  \n block4a_project_bn (BatchNorma  (None, 8, 8, 80)    320         ['block4a_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block4b_expand_conv (Conv2D)   (None, 8, 8, 480)    38400       ['block4a_project_bn[0][0]']     \n                                                                                                  \n block4b_expand_bn (BatchNormal  (None, 8, 8, 480)   1920        ['block4b_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block4b_expand_activation (Act  (None, 8, 8, 480)   0           ['block4b_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block4b_dwconv (DepthwiseConv2  (None, 8, 8, 480)   4320        ['block4b_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block4b_bn (BatchNormalization  (None, 8, 8, 480)   1920        ['block4b_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " block4b_activation (Activation  (None, 8, 8, 480)   0           ['block4b_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n                                                                                                  \n block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n                                                                                                  \n block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n                                                                                                  \n block4b_se_excite (Multiply)   (None, 8, 8, 480)    0           ['block4b_activation[0][0]',     \n                                                                  'block4b_se_expand[0][0]']      \n                                                                                                  \n block4b_project_conv (Conv2D)  (None, 8, 8, 80)     38400       ['block4b_se_excite[0][0]']      \n                                                                                                  \n block4b_project_bn (BatchNorma  (None, 8, 8, 80)    320         ['block4b_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block4b_drop (Dropout)         (None, 8, 8, 80)     0           ['block4b_project_bn[0][0]']     \n                                                                                                  \n block4b_add (Add)              (None, 8, 8, 80)     0           ['block4b_drop[0][0]',           \n                                                                  'block4a_project_bn[0][0]']     \n                                                                                                  \n block4c_expand_conv (Conv2D)   (None, 8, 8, 480)    38400       ['block4b_add[0][0]']            \n                                                                                                  \n block4c_expand_bn (BatchNormal  (None, 8, 8, 480)   1920        ['block4c_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block4c_expand_activation (Act  (None, 8, 8, 480)   0           ['block4c_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block4c_dwconv (DepthwiseConv2  (None, 8, 8, 480)   4320        ['block4c_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block4c_bn (BatchNormalization  (None, 8, 8, 480)   1920        ['block4c_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block4c_activation (Activation  (None, 8, 8, 480)   0           ['block4c_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n                                                                                                  \n block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n                                                                                                  \n block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n                                                                                                  \n block4c_se_excite (Multiply)   (None, 8, 8, 480)    0           ['block4c_activation[0][0]',     \n                                                                  'block4c_se_expand[0][0]']      \n                                                                                                  \n block4c_project_conv (Conv2D)  (None, 8, 8, 80)     38400       ['block4c_se_excite[0][0]']      \n                                                                                                  \n block4c_project_bn (BatchNorma  (None, 8, 8, 80)    320         ['block4c_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block4c_drop (Dropout)         (None, 8, 8, 80)     0           ['block4c_project_bn[0][0]']     \n                                                                                                  \n block4c_add (Add)              (None, 8, 8, 80)     0           ['block4c_drop[0][0]',           \n                                                                  'block4b_add[0][0]']            \n                                                                                                  \n block5a_expand_conv (Conv2D)   (None, 8, 8, 480)    38400       ['block4c_add[0][0]']            \n                                                                                                  \n block5a_expand_bn (BatchNormal  (None, 8, 8, 480)   1920        ['block5a_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block5a_expand_activation (Act  (None, 8, 8, 480)   0           ['block5a_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block5a_dwconv (DepthwiseConv2  (None, 8, 8, 480)   12000       ['block5a_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block5a_bn (BatchNormalization  (None, 8, 8, 480)   1920        ['block5a_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block5a_activation (Activation  (None, 8, 8, 480)   0           ['block5a_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n agePooling2D)                                                                                    \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "                                                                                                  \n block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n                                                                                                  \n block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n                                                                                                  \n block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n                                                                                                  \n block5a_se_excite (Multiply)   (None, 8, 8, 480)    0           ['block5a_activation[0][0]',     \n                                                                  'block5a_se_expand[0][0]']      \n                                                                                                  \n block5a_project_conv (Conv2D)  (None, 8, 8, 112)    53760       ['block5a_se_excite[0][0]']      \n                                                                                                  \n block5a_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block5a_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block5b_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block5a_project_bn[0][0]']     \n                                                                                                  \n block5b_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block5b_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block5b_expand_activation (Act  (None, 8, 8, 672)   0           ['block5b_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block5b_dwconv (DepthwiseConv2  (None, 8, 8, 672)   16800       ['block5b_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block5b_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block5b_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block5b_activation (Activation  (None, 8, 8, 672)   0           ['block5b_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n                                                                                                  \n block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n                                                                                                  \n block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n                                                                                                  \n block5b_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block5b_activation[0][0]',     \n                                                                  'block5b_se_expand[0][0]']      \n                                                                                                  \n block5b_project_conv (Conv2D)  (None, 8, 8, 112)    75264       ['block5b_se_excite[0][0]']      \n                                                                                                  \n block5b_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block5b_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block5b_drop (Dropout)         (None, 8, 8, 112)    0           ['block5b_project_bn[0][0]']     \n                                                                                                  \n block5b_add (Add)              (None, 8, 8, 112)    0           ['block5b_drop[0][0]',           \n                                                                  'block5a_project_bn[0][0]']     \n                                                                                                  \n block5c_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block5b_add[0][0]']            \n                                                                                                  \n block5c_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block5c_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block5c_expand_activation (Act  (None, 8, 8, 672)   0           ['block5c_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block5c_dwconv (DepthwiseConv2  (None, 8, 8, 672)   16800       ['block5c_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block5c_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block5c_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block5c_activation (Activation  (None, 8, 8, 672)   0           ['block5c_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n                                                                                                  \n block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n                                                                                                  \n block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n                                                                                                  \n block5c_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block5c_activation[0][0]',     \n                                                                  'block5c_se_expand[0][0]']      \n                                                                                                  \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " block5c_project_conv (Conv2D)  (None, 8, 8, 112)    75264       ['block5c_se_excite[0][0]']      \n                                                                                                  \n block5c_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block5c_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block5c_drop (Dropout)         (None, 8, 8, 112)    0           ['block5c_project_bn[0][0]']     \n                                                                                                  \n block5c_add (Add)              (None, 8, 8, 112)    0           ['block5c_drop[0][0]',           \n                                                                  'block5b_add[0][0]']            \n                                                                                                  \n block6a_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block5c_add[0][0]']            \n                                                                                                  \n block6a_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block6a_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block6a_expand_activation (Act  (None, 8, 8, 672)   0           ['block6a_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block6a_dwconv_pad (ZeroPaddin  (None, 11, 11, 672)  0          ['block6a_expand_activation[0][0]\n g2D)                                                            ']                               \n                                                                                                  \n block6a_dwconv (DepthwiseConv2  (None, 4, 4, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n D)                                                                                               \n                                                                                                  \n block6a_bn (BatchNormalization  (None, 4, 4, 672)   2688        ['block6a_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block6a_activation (Activation  (None, 4, 4, 672)   0           ['block6a_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n                                                                                                  \n block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n                                                                                                  \n block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n                                                                                                  \n block6a_se_excite (Multiply)   (None, 4, 4, 672)    0           ['block6a_activation[0][0]',     \n                                                                  'block6a_se_expand[0][0]']      \n                                                                                                  \n block6a_project_conv (Conv2D)  (None, 4, 4, 192)    129024      ['block6a_se_excite[0][0]']      \n                                                                                                  \n block6a_project_bn (BatchNorma  (None, 4, 4, 192)   768         ['block6a_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block6b_expand_conv (Conv2D)   (None, 4, 4, 1152)   221184      ['block6a_project_bn[0][0]']     \n                                                                                                  \n block6b_expand_bn (BatchNormal  (None, 4, 4, 1152)  4608        ['block6b_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block6b_expand_activation (Act  (None, 4, 4, 1152)  0           ['block6b_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block6b_dwconv (DepthwiseConv2  (None, 4, 4, 1152)  28800       ['block6b_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block6b_bn (BatchNormalization  (None, 4, 4, 1152)  4608        ['block6b_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block6b_activation (Activation  (None, 4, 4, 1152)  0           ['block6b_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n                                                                                                  \n block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n                                                                                                  \n block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n                                                                                                  \n block6b_se_excite (Multiply)   (None, 4, 4, 1152)   0           ['block6b_activation[0][0]',     \n                                                                  'block6b_se_expand[0][0]']      \n                                                                                                  \n block6b_project_conv (Conv2D)  (None, 4, 4, 192)    221184      ['block6b_se_excite[0][0]']      \n                                                                                                  \n block6b_project_bn (BatchNorma  (None, 4, 4, 192)   768         ['block6b_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block6b_drop (Dropout)         (None, 4, 4, 192)    0           ['block6b_project_bn[0][0]']     \n                                                                                                  \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " block6b_add (Add)              (None, 4, 4, 192)    0           ['block6b_drop[0][0]',           \n                                                                  'block6a_project_bn[0][0]']     \n                                                                                                  \n block6c_expand_conv (Conv2D)   (None, 4, 4, 1152)   221184      ['block6b_add[0][0]']            \n                                                                                                  \n block6c_expand_bn (BatchNormal  (None, 4, 4, 1152)  4608        ['block6c_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block6c_expand_activation (Act  (None, 4, 4, 1152)  0           ['block6c_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block6c_dwconv (DepthwiseConv2  (None, 4, 4, 1152)  28800       ['block6c_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block6c_bn (BatchNormalization  (None, 4, 4, 1152)  4608        ['block6c_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block6c_activation (Activation  (None, 4, 4, 1152)  0           ['block6c_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n                                                                                                  \n block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n                                                                                                  \n block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n                                                                                                  \n block6c_se_excite (Multiply)   (None, 4, 4, 1152)   0           ['block6c_activation[0][0]',     \n                                                                  'block6c_se_expand[0][0]']      \n                                                                                                  \n block6c_project_conv (Conv2D)  (None, 4, 4, 192)    221184      ['block6c_se_excite[0][0]']      \n                                                                                                  \n block6c_project_bn (BatchNorma  (None, 4, 4, 192)   768         ['block6c_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block6c_drop (Dropout)         (None, 4, 4, 192)    0           ['block6c_project_bn[0][0]']     \n                                                                                                  \n block6c_add (Add)              (None, 4, 4, 192)    0           ['block6c_drop[0][0]',           \n                                                                  'block6b_add[0][0]']            \n                                                                                                  \n block6d_expand_conv (Conv2D)   (None, 4, 4, 1152)   221184      ['block6c_add[0][0]']            \n                                                                                                  \n block6d_expand_bn (BatchNormal  (None, 4, 4, 1152)  4608        ['block6d_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block6d_expand_activation (Act  (None, 4, 4, 1152)  0           ['block6d_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block6d_dwconv (DepthwiseConv2  (None, 4, 4, 1152)  28800       ['block6d_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block6d_bn (BatchNormalization  (None, 4, 4, 1152)  4608        ['block6d_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block6d_activation (Activation  (None, 4, 4, 1152)  0           ['block6d_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n                                                                                                  \n block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n                                                                                                  \n block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n                                                                                                  \n block6d_se_excite (Multiply)   (None, 4, 4, 1152)   0           ['block6d_activation[0][0]',     \n                                                                  'block6d_se_expand[0][0]']      \n                                                                                                  \n block6d_project_conv (Conv2D)  (None, 4, 4, 192)    221184      ['block6d_se_excite[0][0]']      \n                                                                                                  \n block6d_project_bn (BatchNorma  (None, 4, 4, 192)   768         ['block6d_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n block6d_drop (Dropout)         (None, 4, 4, 192)    0           ['block6d_project_bn[0][0]']     \n                                                                                                  \n block6d_add (Add)              (None, 4, 4, 192)    0           ['block6d_drop[0][0]',           \n                                                                  'block6c_add[0][0]']            \n                                                                                                  \n block7a_expand_conv (Conv2D)   (None, 4, 4, 1152)   221184      ['block6d_add[0][0]']            \n                                                                                                  \n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": " block7a_expand_bn (BatchNormal  (None, 4, 4, 1152)  4608        ['block7a_expand_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n block7a_expand_activation (Act  (None, 4, 4, 1152)  0           ['block7a_expand_bn[0][0]']      \n ivation)                                                                                         \n                                                                                                  \n block7a_dwconv (DepthwiseConv2  (None, 4, 4, 1152)  10368       ['block7a_expand_activation[0][0]\n D)                                                              ']                               \n                                                                                                  \n block7a_bn (BatchNormalization  (None, 4, 4, 1152)  4608        ['block7a_dwconv[0][0]']         \n )                                                                                                \n                                                                                                  \n block7a_activation (Activation  (None, 4, 4, 1152)  0           ['block7a_bn[0][0]']             \n )                                                                                                \n                                                                                                  \n block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n agePooling2D)                                                                                    \n                                                                                                  \n block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n                                                                                                  \n block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n                                                                                                  \n block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n                                                                                                  \n block7a_se_excite (Multiply)   (None, 4, 4, 1152)   0           ['block7a_activation[0][0]',     \n                                                                  'block7a_se_expand[0][0]']      \n                                                                                                  \n block7a_project_conv (Conv2D)  (None, 4, 4, 320)    368640      ['block7a_se_excite[0][0]']      \n                                                                                                  \n block7a_project_bn (BatchNorma  (None, 4, 4, 320)   1280        ['block7a_project_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n top_conv (Conv2D)              (None, 4, 4, 1280)   409600      ['block7a_project_bn[0][0]']     \n                                                                                                  \n top_bn (BatchNormalization)    (None, 4, 4, 1280)   5120        ['top_conv[0][0]']               \n                                                                                                  \n top_activation (Activation)    (None, 4, 4, 1280)   0           ['top_bn[0][0]']                 \n                                                                                                  \n average_pooling2d_3 (AveragePo  (None, 2, 2, 1280)  0           ['top_activation[0][0]']         \n oling2D)                                                                                         \n                                                                                                  \n flatten_3 (Flatten)            (None, 5120)         0           ['average_pooling2d_3[0][0]']    \n                                                                                                  \n dropout_3 (Dropout)            (None, 5120)         0           ['flatten_3[0][0]']              \n                                                                                                  \n dense_3 (Dense)                (None, 120)          614520      ['dropout_3[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 4,664,091\nTrainable params: 614,520\nNon-trainable params: 4,049,571\n__________________________________________________________________________________________________\n"
                }
            ],
            "execution_count": 27
        },
        {
            "cell_type": "code",
            "source": [
                "m4_model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
            ],
            "metadata": {
                "id": "DAan7sUe1Oe6",
                "azdata_cell_guid": "a5a9ba9a-eb8d-4970-98d3-ea42a3fdd136",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 28
        },
        {
            "cell_type": "code",
            "source": [
                "m4_model.fit(X_train, y_train, epochs=20, batch_size=32, callbacks=[earlystop], validation_data = (X_test, y_test))"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 380
                },
                "executionInfo": {
                    "elapsed": 77538,
                    "status": "error",
                    "timestamp": 1680052687512,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "mJOT7Bp61Q9C",
                "jupyter": {
                    "outputs_hidden": true
                },
                "outputId": "823bb3a9-05e3-48f4-ddc4-8e425ae61314",
                "tags": [],
                "azdata_cell_guid": "9db27834-7e64-45de-aa00-efac9ec189d9",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Epoch 1/20\n256/256 [==============================] - 132s 493ms/step - loss: 4.6895 - accuracy: 0.0698 - val_loss: 4.2525 - val_accuracy: 0.1242\nEpoch 2/20\n256/256 [==============================] - 123s 482ms/step - loss: 2.9189 - accuracy: 0.3174 - val_loss: 4.2859 - val_accuracy: 0.1359\nEpoch 3/20\n256/256 [==============================] - 124s 484ms/step - loss: 2.1195 - accuracy: 0.5002 - val_loss: 4.4182 - val_accuracy: 0.1311\nEpoch 4/20\n256/256 [==============================] - 123s 482ms/step - loss: 1.6712 - accuracy: 0.6133 - val_loss: 4.5286 - val_accuracy: 0.1325\nEpoch 5/20\n256/256 [==============================] - 129s 503ms/step - loss: 1.3647 - accuracy: 0.6901 - val_loss: 4.7122 - val_accuracy: 0.1237\nEpoch 6/20\n256/256 [==============================] - 133s 519ms/step - loss: 1.1605 - accuracy: 0.7347 - val_loss: 4.7792 - val_accuracy: 0.1301\nEpoch 7/20\n256/256 [==============================] - 123s 480ms/step - loss: 1.0138 - accuracy: 0.7753 - val_loss: 4.9163 - val_accuracy: 0.1291\nEpoch 8/20\n256/256 [==============================] - 131s 513ms/step - loss: 0.9312 - accuracy: 0.7941 - val_loss: 4.9463 - val_accuracy: 0.1291\nEpoch 9/20\n256/256 [==============================] - 123s 481ms/step - loss: 0.8113 - accuracy: 0.8221 - val_loss: 5.0560 - val_accuracy: 0.1355\nEpoch 10/20\n256/256 [==============================] - 123s 483ms/step - loss: 0.7720 - accuracy: 0.8299 - val_loss: 5.1718 - val_accuracy: 0.1291\nEpoch 11/20\n256/256 [==============================] - 122s 476ms/step - loss: 0.7299 - accuracy: 0.8366 - val_loss: 5.2716 - val_accuracy: 0.1384\nEpoch 12/20\n256/256 [==============================] - 123s 479ms/step - loss: 0.6906 - accuracy: 0.8444 - val_loss: 5.3406 - val_accuracy: 0.1345\nEpoch 13/20\n256/256 [==============================] - 122s 475ms/step - loss: 0.6635 - accuracy: 0.8526 - val_loss: 5.4629 - val_accuracy: 0.1306\nEpoch 14/20\n256/256 [==============================] - 121s 475ms/step - loss: 0.6342 - accuracy: 0.8546 - val_loss: 5.5860 - val_accuracy: 0.1423\nEpoch 15/20\n256/256 [==============================] - 121s 474ms/step - loss: 0.6040 - accuracy: 0.8658 - val_loss: 5.7332 - val_accuracy: 0.1291\nEpoch 16/20\n256/256 [==============================] - 123s 482ms/step - loss: 0.5884 - accuracy: 0.8657 - val_loss: 5.8782 - val_accuracy: 0.1267\nEpoch 17/20\n256/256 [==============================] - 122s 477ms/step - loss: 0.6090 - accuracy: 0.8543 - val_loss: 5.9510 - val_accuracy: 0.1306\n"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 29,
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x25c1309a650>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 29
        },
        {
            "cell_type": "markdown",
            "source": [
                "Created a process to convert a single image into an array for prediction.\n",
                "\n",
                "This model uses a similar method to the one above that converts all images in the train file and puts them into an empty array."
            ],
            "metadata": {
                "id": "5eu4PSxdDvj4",
                "azdata_cell_guid": "82a2062e-91e1-470c-abe9-852379750831"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "x_predict = np.zeros([128, 128, 3], dtype=np.float32)\n",
                "pred_image = tf.keras.preprocessing.image.load_img('pug.jpg', target_size=(128,128))\n",
                "pred_img_array = tf.keras.preprocessing.image.img_to_array(pred_image)\n",
                "pred_img_array = tf.keras.applications.mobilenet.preprocess_input(pred_img_array)\n",
                "pred_img_array = np.expand_dims(pred_img_array, axis=0)\n",
                "x_predict = pred_img_array"
            ],
            "metadata": {
                "id": "XST_dZii8akN",
                "azdata_cell_guid": "7de4e170-71ac-4fde-a4ce-b6a452a3cab5",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 40
        },
        {
            "cell_type": "markdown",
            "source": [
                "Predict a single image from the one hot encoded labels.\n",
                "This method also reverses the onehot encoding to reveal the original class."
            ],
            "metadata": {
                "id": "5g-MIULRECp5",
                "azdata_cell_guid": "a8582b25-e1fc-44e0-8d69-e4cd231ac148"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "prediction = m1_model.predict(x_predict)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 143,
                    "status": "ok",
                    "timestamp": 1680060548024,
                    "user": {
                        "displayName": "Ray Thibodeaux",
                        "userId": "03354524483193759015"
                    },
                    "user_tz": 300
                },
                "id": "qrYVt8MR_ent",
                "outputId": "c0ecb81c-c66c-4603-d5ea-7cf5aabc52e5",
                "tags": [],
                "azdata_cell_guid": "7e91ceac-efad-4bcf-bda8-465378b0c018",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "1/1 [==============================] - 0s 79ms/step\n"
                }
            ],
            "execution_count": 41
        },
        {
            "cell_type": "markdown",
            "source": [
                "Get the highest probability using the \"argmax\" method. The class with the highest probability is pulled from the array of y labels (pred_y_labels)."
            ],
            "metadata": {
                "azdata_cell_guid": "b110c8c8-7db9-4087-9bd4-fe8fb00b9cad"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "labels_csv = pd.read_csv('labels.csv')\n",
                "breed_labels = pd.Categorical(pd.factorize(labels_csv.breed)[0])\n",
                "pred_y_labels = labels_csv[\"breed\"].unique()\n",
                "\n",
                "pred = np.argmax(prediction, axis=1)\n",
                "\n",
                "print(pred_y_labels[pred])"
            ],
            "metadata": {
                "azdata_cell_guid": "3bd2e238-103f-498e-99e3-5a841f07c746",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "['pug']\n"
                }
            ],
            "execution_count": 44
        }
    ]
}